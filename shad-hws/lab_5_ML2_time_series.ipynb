{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Временные ряды: Гибридная стратегия",
   "id": "a15102d044f40d4b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "В этой задаче вам предстоит реализовать гибридную стратегию для прогнозирования временных рядов. В качестве временного ряда будем использовать данные о дневном спросе разных товаров в магазинах, рассматриваем только 1-й товар из 1-го магазина. Чтобы посмотреть на данные локально, можете скачать их отсюда: https://www.kaggle.com/c/demand-forecasting-kernels-only.\n",
    "\n",
    "1. Функция `read_timeseries` уже реализована. Вы можете использовать ее для локально тестирования.\n",
    "2. В функции `extract_hybrid_strategy_features` необходимо реализовать извлечение фичей из временного ряда согласно гибридной схеме.\n",
    "3. Функция `build_datasets` используется для генерации датасета для каждой модели в гибридной схеме.\n",
    "4. Внутри функции `predict` необходимо реализовать генерацию прогноза с использованием обученных моделей. Обратите внимание, что в процессе генерации новых значений временного ряда необходимо также считать вектор фичей для следующего прогноза. Для этого стоит использовать функцию `exrtact_features`, переданную в аргументах вызова. Важно: внутри predict нужно вызывать extract_features без параметров со значениями по умолчанию (то есть нужно передавать только timeseries и model_idx).\n",
    "5. Реализуйте обучение моделей в теле функции `train_models`. Можно использовать любые модели из sklearn, например, линейную регрессию или градиентный бустинг. Так же очень полезным может оказаться добавление новых фичей, можете подумать про сезонности и даты. Может быть полезно реализовать новую функцию `extract_features`, чтобы получить лучший результат.\n",
    "6. Функция `score_models` используется для оценки качества обученных моделей по метрике MSE. Эта функция уже реализована, Вы можете использовать ее для локальной отладки. Баллы за итоговую модель (55 из 100) будут выставляться обратно пропорционально полученному MSE при обучении 30 моделей (`model_count=30`) - от 0 баллов за $MSE⩾40$ до 55 баллов за $MSE⩽25$.\n",
    "\n",
    "В каждую функцию из шаблона можно добавлять произвольные аргументы с дефолтными значениями.\n",
    "\n"
   ],
   "id": "4aa0bb9f6da170ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T18:44:28.541568Z",
     "start_time": "2024-04-16T18:44:28.311080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import datetime\n",
    "import sklearn\n",
    "import typing as tp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_type = tp.NewType(\"X_type\", np.ndarray)\n",
    "X_row_type = tp.NewType(\"X_row_type\", np.ndarray)\n",
    "Y_type = tp.NewType(\"Y_type\", np.array)\n",
    "TS_type = tp.NewType(\"TS_type\", pd.Series)\n",
    "Model_type = tp.TypeVar(\"Model_type\")\n",
    "\n",
    "\n",
    "def read_timeseries(path_to_df: str = \"train.csv\") -> TS_type:\n",
    "    \"\"\"Функция для чтения данных и получения обучающей и тестовой выборок\"\"\"\n",
    "    df = pd.read_csv(path_to_df)\n",
    "    df = df[(df['store'] == 1) & (df['item'] == 1)]\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    df = df.set_index(\"date\")\n",
    "    ts = df[\"sales\"]\n",
    "    train_ts = ts[:-365]\n",
    "    test_ts = ts[-365:]\n",
    "    return train_ts, test_ts\n",
    "\n",
    "\n",
    "def extract_hybrid_strategy_features(\n",
    "        timeseries: TS_type,\n",
    "        model_idx: int,\n",
    "        window_size: int = 7\n",
    ") -> X_row_type:\n",
    "    \"\"\"\n",
    "    Функция для получения вектора фичей согласно гибридной схеме. На вход подаётся временной ряд\n",
    "    до момента T, функция выделяет из него фичи, необходимые модели под номером model_idx для\n",
    "    прогноза на момент времени T\n",
    "    \n",
    "    Args:\n",
    "        timeseries --- временной ряд до момента времени T (не включительно), pd.Series с датой \n",
    "                       в качестве индекса\n",
    "        model_idx --- индекс модели, то есть номер шага прогноза, \n",
    "                      для которого нужно получить признаки, нумерация с нуля\n",
    "        window_size --- количество последних значений ряда, используемых для прогноза \n",
    "                        (без учёта количества прогнозов с предыдущих этапов)\n",
    "\n",
    "    Returns:\n",
    "        Одномерный вектор фичей для модели с индексом model_idx (np.array), \n",
    "        чтобы сделать прогноз для момента времени T\n",
    "    \"\"\"\n",
    "    if model_idx == 0:\n",
    "        return timeseries[-window_size:].values\n",
    "    \n",
    "    feature_vector = timeseries[-(window_size + model_idx): -model_idx]\n",
    "    return np.concatenate([feature_vector.values, timeseries[-model_idx:].values])\n",
    "\n",
    "\n",
    "def my_extract_features(timeseries: pd.Series, model_idx: int, window_size: int = 7) -> np.ndarray:\n",
    "    if model_idx == 0:\n",
    "        return timeseries[-window_size:].values\n",
    "    else:\n",
    "        extended_window = window_size + model_idx\n",
    "        return timeseries[-extended_window:-model_idx].values\n",
    "\n",
    "\n",
    "def build_datasets(\n",
    "        timeseries: TS_type,\n",
    "        extract_features: tp.Callable[..., X_row_type],\n",
    "        window_size: int,\n",
    "        model_count: int\n",
    ") -> tp.List[tp.Tuple[X_type, Y_type]]:\n",
    "    \"\"\"\n",
    "    Функция для получения обучающих датасетов согласно гибридной схеме\n",
    "    \n",
    "    Args:\n",
    "        timeseries --- временной ряд\n",
    "        extract_features --- функция для генерации вектора фичей\n",
    "        window_size --- количество последних значений ряда, используемых для прогноза\n",
    "        model_count --- количество моделей, используемых для получения предскзаний \n",
    "\n",
    "    Returns:\n",
    "        Список из model_count датасетов, i-й датасет используется для обучения i-й модели \n",
    "        и представляет собой пару из двумерного массива фичей и одномерного массива таргетов\n",
    "    \"\"\"\n",
    "    datasets = []\n",
    "    total_length = len(timeseries)\n",
    "\n",
    "    for model_idx in range(model_count):\n",
    "        X, Y = [], []\n",
    "        # Установим правильное начало и окончание цикла для каждой модели\n",
    "        start_index = 0\n",
    "        end_index = total_length - window_size - model_idx  # Учитываем сдвиг на model_idx вперёд для Y\n",
    "\n",
    "        for i in range(start_index, end_index):\n",
    "            features = extract_features(timeseries[i: i + window_size], model_idx, window_size)\n",
    "            X.append(features)\n",
    "            Y.append(timeseries[i + window_size + model_idx])\n",
    "\n",
    "        datasets.append((np.array(X), np.array(Y)))\n",
    "\n",
    "    return datasets\n",
    "\n",
    "def predict(\n",
    "        timeseries: TS_type,\n",
    "        models: tp.List[Model_type],\n",
    "        extract_features: tp.Callable[..., X_row_type] = my_extract_features\n",
    ") -> TS_type:\n",
    "    \"\"\"\n",
    "    Функция для получения прогноза len(models) следующих значений временного ряда\n",
    "    \n",
    "    Args:\n",
    "        timeseries --- временной ряд, по которому необходимо сделать прогноз на следующие даты\n",
    "        models --- список обученных моделей, i-я модель используется для получения i-го прогноза\n",
    "        extract_features --- функция для генерации вектора фичей. Если вы реализуете свою функцию \n",
    "                             извлечения фичей для конечной модели, передавайте этим аргументом.\n",
    "                             Внутри функции predict функцию extract_features нужно вызывать только\n",
    "                             с аргументами timeseries и model_idx, остальные должны быть со значениями\n",
    "                             по умолчанию\n",
    "\n",
    "    Returns:\n",
    "        Прогноз len(models) следующих значений временного ряда\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    for model_idx, model in enumerate(models):\n",
    "        features = extract_features(timeseries, model_idx)\n",
    "        prediction = model.predict([features])[0]\n",
    "        predictions.append(prediction)\n",
    "        # Расширяем timeseries с новыми прогнозами и индексами\n",
    "        new_index = timeseries.index[-1] + datetime.timedelta(days=1)\n",
    "        timeseries = timeseries.append(pd.Series([prediction], index=[new_index]))\n",
    "    return pd.Series(predictions, index=[timeseries.index[-i] for i in range(len(predictions), 0, -1)])\n",
    "\n",
    "\n",
    "def train_models(\n",
    "        train_timeseries: TS_type,\n",
    "        model_count: int\n",
    ") -> tp.List[Model_type]:\n",
    "    \"\"\"\n",
    "    Функция для получения обученных моделей\n",
    "    \n",
    "    Args:\n",
    "        train_timeseries --- обучающий временной ряд\n",
    "        model_count --- количество моделей для обучения согласно гибридной схеме.\n",
    "                        Прогнозирование должно выполняться на model_count дней вперёд\n",
    "\n",
    "    Returns:\n",
    "        Список из len(datasets) обученных моделей\n",
    "    \"\"\"\n",
    "    models = []\n",
    "\n",
    "    datasets = build_datasets(\n",
    "        train_timeseries,\n",
    "        my_extract_features, \n",
    "        window_size=5,\n",
    "        model_count=model_count\n",
    "    )\n",
    "\n",
    "    for X, y in datasets:\n",
    "        model = LinearRegression()\n",
    "        model.fit(X, y)\n",
    "        models.append(model)\n",
    "\n",
    "    assert len(models) == model_count\n",
    "\n",
    "    return models\n",
    "\n",
    "\n",
    "def score_models(\n",
    "        train_ts: TS_type,\n",
    "        test_ts: TS_type,\n",
    "        models: tp.List[Model_type],\n",
    "        predict: tp.Callable[[TS_type, tp.List[Model_type]], TS_type] = predict\n",
    "):\n",
    "    \"\"\"\n",
    "    Функция для оценки качества обученных моделей по метрике MSE\n",
    "    \n",
    "    Args:\n",
    "        train_ts --- обучающий временной ряд\n",
    "        test_ts --- тестовый временной ряд\n",
    "        models --- список обученных моделей\n",
    "        predict --- функция для получения прогноза временного ряда\n",
    "\n",
    "    Returns:\n",
    "        Усредненное MSE для прогноза моделей по всей тестовой выборке\n",
    "    \"\"\"\n",
    "    predict_len = len(models)\n",
    "    predictions = []\n",
    "    targets = []\n",
    "\n",
    "    for i in range(len(test_ts) - predict_len + 1):\n",
    "        predictions.extend(list(predict(train_ts, models)))\n",
    "        targets.extend(list(test_ts[i:i+predict_len]))\n",
    "        train_ts = train_ts.append(test_ts[i:i+1])\n",
    "\n",
    "    return sklearn.metrics.mean_squared_error(targets, predictions)"
   ],
   "id": "2f392f17ab5f456d",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T02:50:30.944911Z",
     "start_time": "2024-04-15T02:50:27.868207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_build_datasets():\n",
    "    # Загрузка данных\n",
    "    train_ts, _ = read_timeseries(\"demand-forecasting-kernels-only/train.csv\")\n",
    "\n",
    "    # Задаем параметры для тестирования\n",
    "    model_counts = [1, 3, 10 ]  # Примеры количества моделей для тестирования\n",
    "    window_sizes = [5, 7, 10]  # Разные размеры окна для тестирования\n",
    "\n",
    "    # Перебор различных комбинаций параметров\n",
    "    for model_count in model_counts:\n",
    "        for window_size in window_sizes:\n",
    "            # Получение датасетов\n",
    "            datasets = build_datasets(\n",
    "                timeseries=train_ts,\n",
    "                extract_features=extract_hybrid_strategy_features,\n",
    "                window_size=window_size,\n",
    "                model_count=model_count\n",
    "            )\n",
    "\n",
    "            # Проверка каждого датасета\n",
    "            for idx, (X, Y) in enumerate(datasets):\n",
    "                # Проверка размеров массивов\n",
    "                assert X.shape[0] == Y.shape[0], f\"Mismatch in dataset {idx}: X and Y samples count not equal ({X.shape[0]} != {Y.shape[0]})\"\n",
    "                # Проверка размерности X\n",
    "                assert X.shape[1] == window_size, f\"Mismatch in dataset {idx}: X features count not equal to window_size ({X.shape[1]} != {window_size})\"\n",
    "                print(f\"Dataset {idx} with model_count {model_count} and window_size {window_size} passed successfully.\")\n",
    "\n",
    "    print(\"All tests passed successfully.\")\n",
    "\n",
    "# Вызов функции тестирования\n",
    "test_build_datasets()\n"
   ],
   "id": "432fb180696cba41",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_122355/2208024335.py:96: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  Y.append(timeseries[i + window_size + model_idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 0 with model_count 1 and window_size 5 passed successfully.\n",
      "Dataset 0 with model_count 1 and window_size 7 passed successfully.\n",
      "Dataset 0 with model_count 1 and window_size 10 passed successfully.\n",
      "Dataset 0 with model_count 3 and window_size 5 passed successfully.\n",
      "Dataset 1 with model_count 3 and window_size 5 passed successfully.\n",
      "Dataset 2 with model_count 3 and window_size 5 passed successfully.\n",
      "Dataset 0 with model_count 3 and window_size 7 passed successfully.\n",
      "Dataset 1 with model_count 3 and window_size 7 passed successfully.\n",
      "Dataset 2 with model_count 3 and window_size 7 passed successfully.\n",
      "Dataset 0 with model_count 3 and window_size 10 passed successfully.\n",
      "Dataset 1 with model_count 3 and window_size 10 passed successfully.\n",
      "Dataset 2 with model_count 3 and window_size 10 passed successfully.\n",
      "Dataset 0 with model_count 10 and window_size 5 passed successfully.\n",
      "Dataset 1 with model_count 10 and window_size 5 passed successfully.\n",
      "Dataset 2 with model_count 10 and window_size 5 passed successfully.\n",
      "Dataset 3 with model_count 10 and window_size 5 passed successfully.\n",
      "Dataset 4 with model_count 10 and window_size 5 passed successfully.\n",
      "Dataset 5 with model_count 10 and window_size 5 passed successfully.\n",
      "Dataset 6 with model_count 10 and window_size 5 passed successfully.\n",
      "Dataset 7 with model_count 10 and window_size 5 passed successfully.\n",
      "Dataset 8 with model_count 10 and window_size 5 passed successfully.\n",
      "Dataset 9 with model_count 10 and window_size 5 passed successfully.\n",
      "Dataset 0 with model_count 10 and window_size 7 passed successfully.\n",
      "Dataset 1 with model_count 10 and window_size 7 passed successfully.\n",
      "Dataset 2 with model_count 10 and window_size 7 passed successfully.\n",
      "Dataset 3 with model_count 10 and window_size 7 passed successfully.\n",
      "Dataset 4 with model_count 10 and window_size 7 passed successfully.\n",
      "Dataset 5 with model_count 10 and window_size 7 passed successfully.\n",
      "Dataset 6 with model_count 10 and window_size 7 passed successfully.\n",
      "Dataset 7 with model_count 10 and window_size 7 passed successfully.\n",
      "Dataset 8 with model_count 10 and window_size 7 passed successfully.\n",
      "Dataset 9 with model_count 10 and window_size 7 passed successfully.\n",
      "Dataset 0 with model_count 10 and window_size 10 passed successfully.\n",
      "Dataset 1 with model_count 10 and window_size 10 passed successfully.\n",
      "Dataset 2 with model_count 10 and window_size 10 passed successfully.\n",
      "Dataset 3 with model_count 10 and window_size 10 passed successfully.\n",
      "Dataset 4 with model_count 10 and window_size 10 passed successfully.\n",
      "Dataset 5 with model_count 10 and window_size 10 passed successfully.\n",
      "Dataset 6 with model_count 10 and window_size 10 passed successfully.\n",
      "Dataset 7 with model_count 10 and window_size 10 passed successfully.\n",
      "Dataset 8 with model_count 10 and window_size 10 passed successfully.\n",
      "Dataset 9 with model_count 10 and window_size 10 passed successfully.\n",
      "All tests passed successfully.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def test_build_datasets(train_test_ts):\n",
    "    train_ts, _ = train_test_ts\n",
    "\n",
    "    # Предположим, что у нас есть параметры для тестирования\n",
    "    model_count, window_size = 3, 5\n",
    "\n",
    "    # Получение датасетов от вашей и эталонной реализации\n",
    "    p_datasets = build_datasets(\n",
    "        timeseries=train_ts[-100:],\n",
    "        extract_features=extract_hybrid_strategy_features,\n",
    "        model_count=model_count,\n",
    "        window_size=window_size\n",
    "    )\n",
    "\n",
    "    # j_datasets = jury_solution.build_datasets(\n",
    "    #     timeseries=train_ts[-100:],\n",
    "    #     extract_features=jury_solution.extract_hybrid_strategy_features,\n",
    "    #     model_count=model_count,\n",
    "    #     window_size=window_size\n",
    "    # )\n",
    "    # \n",
    "    # assert len(p_datasets) == len(j_datasets)\n",
    "\n",
    "\n",
    "    for i, (p_d, j_d) in enumerate(zip(p_datasets, j_datasets)):\n",
    "        assert len(p_d) == 2 and len(j_d) == 2, \"Wrong dataset element count\"\n",
    "        assert p_d[0].shape == j_d[0].shape, f\"Mismatch in shape of X at dataset {i}\"\n",
    "        assert p_d[1].shape == j_d[1].shape, f\"Mismatch in shape of Y at dataset {i}\"\n",
    "        assert np.allclose(p_d[0], j_d[0]), f\"Wrong X_{i}\"\n",
    "        assert np.allclose(p_d[1], j_d[1]), f\"Wrong Y_{i}\"\n",
    "\n",
    "    print(\"All datasets match successfully.\")\n"
   ],
   "id": "8cb3bfba1af12f75",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c742819",
   "metadata": {},
   "source": [
    "# Лабораторная работа 7. Обучение без учителя\n",
    "\n",
    "Результат лабораторной работы − отчет. Мы предпочитаем принимать отчеты в формате ноутбуков IPython (ipynb-файл). Постарайтесь сделать ваш отчет интересным рассказом, последовательно отвечающим на вопросы из заданий. Помимо ответов на вопросы, в отчете также должен быть код, однако чем меньше кода, тем лучше всем: нам − меньше проверять, вам — проще найти ошибку или дополнить эксперимент. При проверке оценивается четкость ответов на вопросы, аккуратность отчета и кода.\n",
    "\n",
    "## Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 15 баллов. Сдавать задание после указанного срока сдачи нельзя. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов и понижают карму. Если вы нашли решение какого-то из заданий в открытом источнике, необходимо прислать ссылку на этот источник (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, нам необходима ссылка на источник)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4267464f",
   "metadata": {},
   "source": [
    "## EM-алгоритм"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aec3aaa",
   "metadata": {},
   "source": [
    "### Краудсорсинг\n",
    "\n",
    "Разметка данных — одна из самых трудозатратных задач в машинном обучении. Краудсорсинг позволяет распределить эту задачу на тысячи исполнителей, каждый из которых подготавливает небольшую часть датасета (подробнее <a href=\"https://academy.yandex.ru/posts/chto-takoe-kraudsorsing-i-pochemu-emu-nuzhno-uchitsya\">тут</a>).\n",
    "\n",
    "Пользователи могут допускать ошибки при разметке, кроме того, среди пользователей могут быть боты. Если мы попросим разметить каждый объект только одного пользователя, то с большой вероятностью получим не достаточно качественную разметку. Обычно каждый объект размечают несколько пользователей.\n",
    "\n",
    "Результаты разметки нужно обработать. Самый простой метод *голос большинства*. Он заключается в том, что для каждого объекта нужно взять тот класс, который чаще всего ставили пользователи данному объекту. Это достаточно хороший метод, но он не учитывает различные особенности пользователей. Далее рассмотрим метод, который позволяет оценивать вероятность того, что разметчик ошибся.\n",
    "\n",
    "### Метод Дэвида-Скина (Dawid, Skene, 1979)\n",
    "\n",
    "Мы имеем в качестве данных $n_{ik}^u$ &mdash; количество раз, при которых разметчик $u \\in U$ поставил класс $k \\in K$ объекту $i \\in I$ (возможно, разметчик видел этот объект несколько раз). Обозначим $Y_{ik} = I\\{\\text{объект $i$ класса $k$}\\}$, это наши латентные величины. \n",
    "\n",
    "В качестве параметров имеем\n",
    "* $\\pi_{k\\ell}^u$ &mdash; вероятность того, что разметчик $u$ поставил класс $\\ell$ вместо правильного класса $k$. \n",
    "* $\\rho_k$ &mdash; вероятность класса $k$.\n",
    "\n",
    "Поймём, какой будет функция неполного правдоподобия в этой задаче. Прежде всего,\n",
    "\n",
    "$$p_{\\pi,p}(N, Y) = \\prod_{i\\in I}p(N_i, Y_i),$$\n",
    "\n",
    "Если $k$ - номер класса $i$-го объекта, то\n",
    "\n",
    "$$p(N_i, Y_i)=\\underbrace{p(\\text{объект $i$ класса $k$})}_{=\\rho_k}p(N_i\\mid\\text{объект $i$ класса $k$})$$\n",
    "\n",
    "(значения $Y_{it}$ однозначно определяются номером истинного класса, поэтому справа $Y_i$ пропадает). Далее, мы считаем, что разметчики действуют независимо, поэтому\n",
    "\n",
    "$$p(N_i\\mid\\text{объект $i$ класса $k$}) = \\prod_{u\\in U}p(N_i^u\\mid\\text{объект $i$ класса $k$}).$$\n",
    "\n",
    "Разберёмся с величиной $p(N_i^u\\mid\\text{объект $i$ класса $k$})$. Она отвечает за то, какие классы $u$-й разметчик ставил $i$-му объекту. Мы считаем, что встречи разметчика с объектом упорядочены по времени, тогда\n",
    "\n",
    "$$p(\\text{$u$-й разметчик отнёс $i$-й объект к классам $k'_1,\\ldots,k'_r$}\\mid\\text{объект $i$ класса $k$}) =$$\n",
    "\n",
    "$$=\\prod_{s}p(\\text{в $s$-ю встречу с $i$-м объектом $u$-й разметчик отнёс его к классу $k'_s$}\\mid\\text{объект $i$ класса $k$})$$\n",
    "\n",
    "Эту вероятность можно переписать в виде\n",
    "\n",
    "$$\\prod_{\\ell \\in K} \\left( \\pi_{k\\ell}^u \\right)^{n_{i\\ell}^u},$$ - ненормированная вероятность\n",
    "\n",
    "а итоговое неполное правдоподобие предстаёт в виде\n",
    "\n",
    "$$p_{\\pi,p}(N, Y) = \\prod_{i\\in I}\\prod_{k \\in K} \\left( \\rho_k \\prod_{u\\in U} \\prod_{\\ell \\in K} \\left( \\pi_{k\\ell}^u \\right)^{n_{i\\ell}^u} \\right)^{Y_{ik}}$$\n",
    "\n",
    "Его нам нужно максимизировать по $\\pi$ и $\\rho$\n",
    "\n",
    "**Пояснение к формуле:** \n",
    "\n",
    "Вне больших скобок фиксируются объект и его класс, сама скобка возводится в степень 1, если рассматривается правильный класс объекта, и в степень 0 иначе. Внутри сначала записана вероятность того, что объект имеет данный класс, а затем &mdash; перебор по всем пользователям и всем классам, которые мог поставить данный пользователь. Наконец, записывается вероятность того, что пользователь нашему объекту поставил некоторый класс, которая возводится в степень того, сколько раз он поставил этот класс. Например, если пользователь видел изображение котика 5 раз, при этом 3 раза он сказал, что котик, а два раза &mdash; песик, то вероятность $\\pi_{cat,cat}^u$ для данного котика учтется 3 раза, а вероятность $\\pi_{cat,dog}^u$ &mdash; 2 раза."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb326b9",
   "metadata": {},
   "source": [
    "**Задание 1 (2 балл)**\n",
    "\n",
    "Распишите итерационную процедуру EM-алгоритма и значение ELBO в методе Дэвида-Скина."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T09:06:18.444761Z",
     "start_time": "2024-06-19T09:06:18.078129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import logsumexp, softmax"
   ],
   "id": "6f4758f6dda3fafd",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "473bb9fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T09:06:18.458025Z",
     "start_time": "2024-06-19T09:06:18.446055Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import coo_matrix, dok_matrix\n",
    "from scipy.special import softmax\n",
    "\n",
    "class DawidSkene:\n",
    "    def __init__(self, crowd_labels: pd.DataFrame):\n",
    "        self.crowd_labels = crowd_labels\n",
    "\n",
    "        # Create a mapping from user/item/label to their corresponding indices\n",
    "        self.user_mapping = {user: i for i, user in enumerate(crowd_labels['C1'].unique())}\n",
    "        self.item_mapping = {item: i for i, item in enumerate(crowd_labels['C2'].unique())}\n",
    "        self.label_mapping = {label: i for i, label in enumerate(crowd_labels['C3'].unique())}\n",
    "\n",
    "        self.grouped = crowd_labels.groupby(['C1', 'C2', 'C3']).size().reset_index(name='counts')\n",
    "\n",
    "        # Initialize the joint_occurrence dictionary\n",
    "        self.joint_occurrence = {} #with respect to item for faster E-step\n",
    "        self.joint_occurrence_u = {} #with respect to user for faster M-step\n",
    "        for _, row in self.grouped.iterrows():\n",
    "            i = self.user_mapping[row['C1']]\n",
    "            j = self.item_mapping[row['C2']]\n",
    "            k = self.label_mapping[row['C3']]\n",
    "            if j not in self.joint_occurrence:\n",
    "                self.joint_occurrence[j] = {}\n",
    "            self.joint_occurrence[j][(i, k)] = row['counts']\n",
    "            if i not in self.joint_occurrence_u:\n",
    "                self.joint_occurrence_u[i] = {}\n",
    "            self.joint_occurrence_u[i][(j, k)] = row['counts']\n",
    "\n",
    "\n",
    "        # Initialize item-label probabilities uniformly\n",
    "        #self.rho = np.full(len(self.label_mapping), np.log(1 / len(self.label_mapping)))\n",
    "        self.rho = np.random.rand(len(self.label_mapping))\n",
    "        self.rho = np.log(self.rho/np.sum(self.rho))\n",
    "\n",
    "        # Initialize labeler confusion matrices uniformly. On fix user\n",
    "        self.pi = np.random.rand(len(self.user_mapping), len(self.label_mapping), len(self.label_mapping))\n",
    "        self.pi = np.log(self.pi/np.sum(self.pi, axis=2, keepdims=True))\n",
    "        # self.pi = np.full(\n",
    "        #     (len(self.user_mapping), len(self.label_mapping), len(self.label_mapping)),\n",
    "        #     np.log(1 / len(self.label_mapping) ** 2)\n",
    "        # )\n",
    "        # Initialize the item_label_prob array\n",
    "        self.q = np.zeros((len(self.item_mapping), len(self.label_mapping)))\n",
    "\n",
    "    def e_step(self):\n",
    "        # Compute the item_label_prob array using the current parameter estimates\n",
    "        for j in range(len(self.item_mapping)):\n",
    "            sum_pi = np.zeros((len(self.label_mapping),))\n",
    "            for k in range(len(self.label_mapping)):\n",
    "                for (i, el), v in self.joint_occurrence[j].items():\n",
    "                    sum_pi[k] += self.joint_occurrence[j][(i, el)] * self.pi[i, k, el]\n",
    "            self.q[j, :] = softmax(self.rho + sum_pi, axis=0)\n",
    "\n",
    "    def m_step(self):\n",
    "        self.rho = np.log(np.mean(self.q, axis=0))\n",
    "        for u in range(len(self.user_mapping)):\n",
    "            sum_q = np.full((len(self.label_mapping), len(self.label_mapping)), 1e-8) # np.zeros((len(self.label_mapping), len(self.label_mapping)))\n",
    "            denom = 0\n",
    "            for (i,r), v in self.joint_occurrence_u[u].items():\n",
    "                denom += v\n",
    "                sum_q[:, r] += v * self.q[i, :]\n",
    "            self.pi[u] = np.log(sum_q / denom) # np.log(np.clip(sum_q / denom, 1e-6, None))\n",
    "\n",
    "    def predict(self):\n",
    "        data = []\n",
    "        for item, i in self.item_mapping.items():\n",
    "            data.append({'object': item, 'prediction': np.argmax(self.q[i, :])})\n",
    "        df = pd.DataFrame(data, columns=['object', 'prediction'])\n",
    "        return df\n",
    "        # df = pd.DataFrame(columns=['item', 'label'])\n",
    "        # for item, i in self.item_mapping.items():\n",
    "        #     df = df.append({'item': item, 'label': np.argmax(self.q[i, :])}, ignore_index=True)\n",
    "        # return df\n",
    "\n",
    "    # Format the DataFrame to match the required output format\n",
    "    def run(self, n_iter):\n",
    "        for _ in range(n_iter):\n",
    "            self.e_step()\n",
    "            self.m_step()\n",
    "        return self.predict()\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "98c0209d",
   "metadata": {},
   "source": [
    "**Задание 2 (3 балла)** \n",
    "\n",
    "Реализуйте следующие методы агрегации результатов разметки в краудсорсинге:\n",
    "\n",
    "* голосование по большинству;\n",
    "* метод Дэвида-Скина.\n",
    "\n",
    "Оба метода должны возвращать вероятность принадлежности объекта каждому из классов (итоговая метка получается выбором класса с наибольшей оценкой вероятности). \n",
    "\n",
    "Заметим, что метод голосования по большинству можно реализовать с помощью одной агрегирующей функцией `pandas.crosstab`, а метод Дэвида-Скина основывается на EM-алгоритме (при реализации стоит учесть, что EM-алгоритм сходится в локальные оптимумы, то есть его стоит запускать из разных начальных приближений).\n",
    "\n",
    "Примените эти два метода к датасетам *Toloka Aggregation Relevance 2* и *Toloka Aggregation Relevance 5*, которые можно скачать <a href=\"https://toloka.ai/ru/datasets\">тут</a>, и сравните их между собой. \n",
    "\n",
    "Обратите внимание, что в последнем датасете 5 различных меток, причем некоторые объекты в датасете имеют не один, а несколько правильных ответов. Любой из таких ответов считается правильным."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f2358e-3154-45c8-8879-a14475a82443",
   "metadata": {},
   "source": [
    "**В Я.Контест нужно загрузить только .csv файлы в следующем формате.**"
   ]
  },
  {
   "cell_type": "code",
   "id": "523abbfa-e72c-4af2-8fad-4811b58f82fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T09:06:18.460713Z",
     "start_time": "2024-06-19T09:06:18.459098Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "b976e136",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T09:06:20.060681Z",
     "start_time": "2024-06-19T09:06:18.462133Z"
    }
   },
   "source": [
    "def majority_vote_agg(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregates crowd-sourced labels using majority voting.\n",
    "    \n",
    "    Args:\n",
    "    df (pd.DataFrame): DataFrame containing columns ['C2', 'C1', 'C3'].\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with columns ['object', 'prediction'].\n",
    "    \"\"\"\n",
    "    # Create a crosstab of votes\n",
    "    crosstab = pd.crosstab(df[item_col], df[label_col])\n",
    "\n",
    "    # Determine the class with the highest probability\n",
    "    crosstab['prediction'] = crosstab.idxmax(axis=1).astype(int)\n",
    "\n",
    "    # Rename columns to match the required format\n",
    "    crosstab.reset_index(inplace=True)\n",
    "    crosstab.rename(columns={item_col: 'object'}, inplace=True)\n",
    "\n",
    "    # Select only the necessary columns\n",
    "    result = crosstab[['object', 'prediction']]\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Load the datasets\n",
    "crowd_labels = pd.read_csv('download/TlkAgg2/crowd_labels.tsv', sep='\\t', header=None,\n",
    "                           names=['C1', 'C2', 'C3'])\n",
    "gold_labels = pd.read_csv('download/TlkAgg2/golden_labels.tsv', sep='\\t', header=None, names=['C2', 'C3'])\n",
    "\n",
    "# Define column names based on the actual data\n",
    "item_col = 'C2'  # task_id\n",
    "labeler_col = 'C1'  # worker_id\n",
    "label_col = 'C3'  # label\n",
    "\n",
    "# Apply Majority Voting\n",
    "majority_result = majority_vote_agg(crowd_labels)\n",
    "majority_result.sort_index(inplace=True)\n",
    "majority_result.to_csv('majority_result.csv', sep=',', index=False)\n",
    "print(\"\\nMajority Voting Result:\")\n",
    "print(majority_result.head())\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Majority Voting Result:\n",
      "C3 object  prediction\n",
      "0      t0           1\n",
      "1      t1           1\n",
      "2     t10           1\n",
      "3    t100           0\n",
      "4   t1000           0\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T09:06:20.068626Z",
     "start_time": "2024-06-19T09:06:20.061396Z"
    }
   },
   "cell_type": "code",
   "source": "majority_result",
   "id": "a6752e3e60de9e9d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C3    object  prediction\n",
       "0         t0           1\n",
       "1         t1           1\n",
       "2        t10           1\n",
       "3       t100           0\n",
       "4      t1000           0\n",
       "...      ...         ...\n",
       "99314  t9995           1\n",
       "99315  t9996           0\n",
       "99316  t9997           0\n",
       "99317  t9998           0\n",
       "99318  t9999           1\n",
       "\n",
       "[99319 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>C3</th>\n",
       "      <th>object</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99314</th>\n",
       "      <td>t9995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99315</th>\n",
       "      <td>t9996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99316</th>\n",
       "      <td>t9997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99317</th>\n",
       "      <td>t9998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99318</th>\n",
       "      <td>t9999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99319 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T09:06:20.215444Z",
     "start_time": "2024-06-19T09:06:20.069580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "crowd_labels = pd.read_csv('download/TlkAgg2/crowd_labels.tsv', sep='\\t', header=None, names=['C1', 'C2', 'C3'])\n",
    "crowd_labels"
   ],
   "id": "b29d05f93f9a2bcd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           C1      C2  C3\n",
       "0        w851  t30685   1\n",
       "1       w6991  t30008   0\n",
       "2       w2596  t36316   0\n",
       "3       w5507  t15145   1\n",
       "4       w2982  t44785   1\n",
       "...       ...     ...  ..\n",
       "475531  w4660  t62250   1\n",
       "475532  w6630  t46626   0\n",
       "475533  w4605  t93513   1\n",
       "475534  w1928  t29002   0\n",
       "475535  w5375  t49052   1\n",
       "\n",
       "[475536 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>w851</td>\n",
       "      <td>t30685</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w6991</td>\n",
       "      <td>t30008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>w2596</td>\n",
       "      <td>t36316</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>w5507</td>\n",
       "      <td>t15145</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>w2982</td>\n",
       "      <td>t44785</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475531</th>\n",
       "      <td>w4660</td>\n",
       "      <td>t62250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475532</th>\n",
       "      <td>w6630</td>\n",
       "      <td>t46626</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475533</th>\n",
       "      <td>w4605</td>\n",
       "      <td>t93513</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475534</th>\n",
       "      <td>w1928</td>\n",
       "      <td>t29002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475535</th>\n",
       "      <td>w5375</td>\n",
       "      <td>t49052</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>475536 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T09:06:40.287541Z",
     "start_time": "2024-06-19T09:06:20.216865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Apply Dawid-Skene Method\n",
    "dawid_skene = DawidSkene(crowd_labels)\n",
    "result_df = dawid_skene.run(n_iter=5)\n",
    "\n",
    "# Format the DataFrame to match the required output format\n",
    "formatted_result = result_df.rename(columns={item_col: 'object', label_col: 'prediction'})[['object', 'prediction']]\n",
    "formatted_result['prediction'] = formatted_result['prediction'].astype(int)\n",
    "formatted_result = formatted_result.sort_values(by='object')\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(\"\\nDawid-Skene Result for TlkAgg2 (First 5 Rows):\")\n",
    "print(formatted_result.head())\n",
    "\n",
    "# Optionally, save the result to a CSV file\n",
    "formatted_result.to_csv('dawid_skene_results.csv', index=False, sep=',')"
   ],
   "id": "1948c1797f632d57",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dawid-Skene Result for TlkAgg2 (First 5 Rows):\n",
      "   object  prediction\n",
      "0  t30685           1\n",
      "1  t30008           1\n",
      "2  t36316           1\n",
      "3  t15145           1\n",
      "4  t44785           1\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T09:09:31.910354Z",
     "start_time": "2024-06-19T09:09:31.836935Z"
    }
   },
   "cell_type": "code",
   "source": "formatted_result.sort_values(by='object').head(10)",
   "id": "f1a6fdcd757249f3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       object  prediction\n",
       "52887      t0           1\n",
       "29893      t1           1\n",
       "13040     t10           1\n",
       "63391    t100           1\n",
       "22532   t1000           1\n",
       "71287  t10000           1\n",
       "37868  t10001           1\n",
       "57988  t10002           1\n",
       "14406  t10003           1\n",
       "39225  t10004           1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52887</th>\n",
       "      <td>t0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29893</th>\n",
       "      <td>t1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13040</th>\n",
       "      <td>t10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63391</th>\n",
       "      <td>t100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22532</th>\n",
       "      <td>t1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71287</th>\n",
       "      <td>t10000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37868</th>\n",
       "      <td>t10001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57988</th>\n",
       "      <td>t10002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14406</th>\n",
       "      <td>t10003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39225</th>\n",
       "      <td>t10004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T09:06:40.487791Z",
     "start_time": "2024-06-19T09:06:40.288218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def majority_vote_agg5(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregates crowd-sourced labels using majority voting.\n",
    "    \n",
    "    Args:\n",
    "    df (pd.DataFrame): DataFrame containing columns ['worker_id', 'task_id', 'label'].\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with columns ['object', 'prediction'].\n",
    "    \"\"\"\n",
    "    # Define column names explicitly\n",
    "    item_col = 'task_id'\n",
    "    label_col = 'label'\n",
    "\n",
    "    # Create a crosstab of votes\n",
    "    crosstab = pd.crosstab(df[item_col], df[label_col])\n",
    "\n",
    "    # Determine the class with the highest probability\n",
    "    crosstab['prediction'] = crosstab.idxmax(axis=1).astype(int)\n",
    "\n",
    "    # Rename columns to match the required format\n",
    "    crosstab.reset_index(inplace=True)\n",
    "    crosstab.rename(columns={item_col: 'object'}, inplace=True)\n",
    "\n",
    "    # Select only the necessary columns\n",
    "    result = crosstab[['object', 'prediction']]\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Load the datasets for TlkAgg5\n",
    "crowd_labels = pd.read_csv('download/TlkAgg5/tlk_agg5_crowd_labels.tsv', sep='\\t', header=None,\n",
    "                           names=['worker_id', 'task_id', 'label'])\n",
    "gold_labels = pd.read_csv('download/TlkAgg5/tlk_agg5_golden_labels.tsv', sep='\\t', header=None,\n",
    "                          names=['task_id', 'label'])\n",
    "\n",
    "# Apply Majority Voting\n",
    "majority_result_tlkagg5 = majority_vote_agg5(crowd_labels)\n",
    "majority_result_tlkagg5.sort_index(inplace=True)\n",
    "majority_result_tlkagg5.head()"
   ],
   "id": "8334f08b47a0ff08",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'download/TlkAgg5/tlk_agg5_crowd_labels.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 32\u001B[0m\n\u001B[1;32m     28\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n\u001B[1;32m     31\u001B[0m \u001B[38;5;66;03m# Load the datasets for TlkAgg5\u001B[39;00m\n\u001B[0;32m---> 32\u001B[0m crowd_labels \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdownload/TlkAgg5/tlk_agg5_crowd_labels.tsv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;130;43;01m\\t\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     33\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mnames\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mworker_id\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtask_id\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlabel\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     34\u001B[0m gold_labels \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdownload/TlkAgg5/tlk_agg5_golden_labels.tsv\u001B[39m\u001B[38;5;124m'\u001B[39m, sep\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124m'\u001B[39m, header\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     35\u001B[0m                           names\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtask_id\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     37\u001B[0m \u001B[38;5;66;03m# Apply Majority Voting\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/5_ITMO/deep-learning/deep-learning-practice/venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m   1013\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m   1014\u001B[0m     dialect,\n\u001B[1;32m   1015\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1022\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m   1023\u001B[0m )\n\u001B[1;32m   1024\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m-> 1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/5_ITMO/deep-learning/deep-learning-practice/venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    617\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    619\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 620\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    622\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m~/Documents/5_ITMO/deep-learning/deep-learning-practice/venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m   1617\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1619\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1620\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/5_ITMO/deep-learning/deep-learning-practice/venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1878\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[1;32m   1879\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1880\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1881\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1882\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1883\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1884\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1885\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1886\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1887\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1888\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1889\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1890\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1891\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[0;32m~/Documents/5_ITMO/deep-learning/deep-learning-practice/venv/lib/python3.11/site-packages/pandas/io/common.py:873\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    868\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    869\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    870\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    871\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m    872\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[0;32m--> 873\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    874\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    875\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    876\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    877\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    878\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    879\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    880\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    881\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m    882\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'download/TlkAgg5/tlk_agg5_crowd_labels.tsv'"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "majority_result_tlkagg5.head()",
   "id": "652bc07b74d86b40",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "majority_result_tlkagg5.tail()\n",
   "id": "484143e91a3c9f17",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "076f5dce",
   "metadata": {},
   "source": [
    "**Задание 3 (1 балл)** \n",
    "\n",
    "Попробуйте в методе Дэвида-Скина в качестве начального приближения вероятностей классов для каждого объекта подавать те вероятности, которые посчитаны методом голосования по большинству, и провести сначала M-шаг."
   ]
  },
  {
   "cell_type": "code",
   "id": "9d566f9f",
   "metadata": {},
   "source": [
    "class DawidSkeneWithMVInit(DawidSkene):\n",
    "    def initialize_params(self):\n",
    "\n",
    "# your code here"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f5f9f9a8",
   "metadata": {},
   "source": [
    "Далее мы будем работать с таблицей `vacancies.csv` и нам нужно подготовить данные для работы, а именно сделайте следующее:\n",
    "    \n",
    "- Разбейте данные на обучающую выборку (строки, не содержащие метки кластеров) и тестовую (строки, содержащие метки кластеров)\n",
    "- Предобработайте текст, содержащийся в колонках *name* и *description* (уберите артефакты, нормализуйте и т.д.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784bbc1c",
   "metadata": {},
   "source": [
    "### Тематическое моделирование\n",
    "\n",
    "Тематическое моделирование заключается в поиске тем $T$, которые хорошо бы описывали документы $D$ со словарём $W$. Большинство тематических моделей оперирует данными в формате \"мешка слов\", т.е. учитывают только частоты слов в документах, а не их порядок. Одной из простейших тематических моделей является [PLSA](https://en.wikipedia.org/wiki/Probabilistic_latent_semantic_analysis), которая приводит к задаче стохастического матричного разложения: \n",
    "\n",
    "$$F \\approx \\Phi \\times \\Theta$$\n",
    "где\n",
    "- $F_{W \\times D}$— матрица распределений слов в документах (нормированные частоты)\n",
    "- $\\Phi_{W \\times T}$ — матрица распределений слов в темах (модель)\n",
    "- $\\Theta_{T \\times D}$ — матрица распределений тем в документах (результат применения модели к обучающим данным)\n",
    "\n",
    "Можно сказать, что алгоритмы тематического моделирования производят мягкую бикластеризацию данных:\n",
    " - *мягкую*, так как объекты относятся не строго к одному кластеру, а к нескольким с разными вероятностями\n",
    " - *бикластеризацию*, так как модель одновременно кластеризует слова по темам и темы по документам.\n",
    " \n",
    " С вероятностной точки зрения, задача обучения модели PLSA ставится как максимизация неполного правдоподобия по параметам $\\Phi$ и $\\Theta$. ЕМ-алгоритм для модели PLSA заключается в повторении двух шагов:\n",
    "\n",
    "- **Е-шаг** — оценка распределений тем для каждого слова в каждом документе по параметрам $\\Phi$ и $\\Theta$ (шаг 6);\n",
    "- **М-шаг** — обновление параметров $\\Phi$ и $\\Theta$ на основе полученных оценок (шаги 7 и 9).\n",
    "\n",
    "Существуют различные модификации итерационного процесса, позволяющие снизить расходы по памяти. В данном случае, мы избежим хранения трехмерной матрицы $p_{tdw}$, сразу пересчитывая $\\Theta$ для текущего документа и аккумулируя счетчики $n_{wt}$ для последующего пересчета $\\Phi$.\n",
    "\n",
    "Псевдокод алгоритма записывается следующим образом:\n",
    "\n",
    "1. Инициализировать $\\phi_{wt}^0$ для всех $w \\in W$, $t \\in T$ и $\\theta_{td}^0$ для всех $t \\in T$, $d \\in D$\n",
    "2. Внешний цикл по итерациям $i = 1 ... max\\_iter$:\n",
    "3. $\\quad$ $n_{wt}^i := 0$, $n_t^i := 0$ для всех $w \\in W$ и $t \\in T$ \n",
    "4. $\\quad$ Внутренний цикл по документам $d \\in D$  \n",
    "5. $\\qquad$ $Z_w := \\sum_{t \\in T} \\phi_{wt}^{i-1}\\theta_{td}^{i-1}$ для всех $w \\in d$ $\\cfrac{}{}$\n",
    "6. $\\qquad$ $p_{tdw} := \\cfrac{ \\phi_{wt}^{i-1}\\theta_{td}^{i-1} }{ Z_w }$ (**E-шаг**)\n",
    "7. $\\qquad$ $\\theta_{td}^{i} := \\cfrac{ \\sum_{w \\in d} n_{dw} p_{tdw} }{ n_d }$ для всех $t \\in T$ (**M-шаг**)\n",
    "8. $\\qquad$ Увеличить $n_{wt}^i$ и $n_t^i$ на $n_{dw} p_{tdw}$ для всех $w \\in W$ и $t \\in T$\n",
    "9. $\\quad \\phi_{wt}^i := \\cfrac{n_{wt}^i}{n_t^i}$ для всех $w \\in W$ и $t \\in T$ (**M-шаг**)\n",
    "\n",
    "Обозначения:\n",
    " - $p_{tdw}$ — вероятность темы $t$ для слова $w$ в документе $d$\n",
    " - $\\phi_{wt}$ — элемент матрицы $\\Phi$, соответствующий вероятности слова $w$ в теме $t$\n",
    " - $\\theta_{td}$ — элемент матрицы $\\Theta$, соответствующий вероятности темы $t$ в документе $d$\n",
    " - $n_{wt}$ — элемент матрицы счётчиков отнесения слова $w$ к теме $t$ (путем нормирования этой матрицы получается матрица $\\Phi$)\n",
    " - $Z_w$ — элемент вектора вспомогательных переменных, соответствующий слову $w$\n",
    " - $n_t$ — вектор нормировочных констант для матрицы $n_{wt}$\n",
    " - $n_d$ — вектор нормировочных констант для матрицы $n_{dw}$\n",
    " - $n$ — суммарное число слов в коллекции\n",
    "\n",
    "Для оценивания качества построенной модели и контроля сходимости процесса обучения обычно используют [перплексию](http://www.machinelearning.ru/wiki/images/8/88/Voron-iip9-talk.pdf):\n",
    "\n",
    "$$\\mathcal{P} = \\exp\\bigg(- \\frac{\\mathcal{L}}{n} \\bigg) = \\exp\\bigg(- \\cfrac{1}{n}\\sum_{d \\in D}\\sum_{w \\in d} n_{dw} \\ln \\big(\\sum_{t \\in T}\\phi_{wt}\\theta_{td} \\big)\\bigg)$$\n",
    "\n",
    "Это традиционная мера качества в тематическом моделировании, которая основана на правдоподобии модели $\\mathcal{L}$. Число итераций $max\\_iter$ в алгоритме обучения следует выбирать достаточным для того, чтобы перплексия перестала существенно убывать. Однако известно, что перплексия плохо отражает интерпретируемость найденных тем, поэтому помимо нее обычно используются дополнительные меры или экспертные оценки.\n",
    "\n",
    "**Рекомендации к реализации:**\n",
    "\n",
    "- При делении на нулевые значения нужно просто заменить частное на ноль.\n",
    "- ЕМ-алгоритм стоит реализовывать с использованием векторных операций. Для проверки корректности реализации сперва можно написать скалярную версию, после чего векторизовать её, удостоверившись, что обе реализации дают одинаковый результат. Невекторизованный алгоритм может работать в сотни раз медленнее векторизованного, и его использование может привести к невозможности выполнения задания.\n",
    "- Итерационный процесс следует начинать, инициализировав матрицы $\\Phi$ и $\\Theta$. Инициализация может быть случайной, важно не забыть отнормировать столбцы матриц.\n",
    "- Неэффективная реализация перплексии может в разы замедлить работу алгоритма."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8d5d52",
   "metadata": {},
   "source": [
    "**Задание 4 (3 балла)** \n",
    "\n",
    "Реализуйте описанный выше ЕМ-алгоритм для модели *PLSA* и добавьте в вашу реализацию подсчёт перплексии. \n",
    "\n",
    "Примените ваш алгоритм к подготовленным ранее данным (объедините текст из колонок *name* и *description*), рассмотрев число тем T = 5, а также:\n",
    "\n",
    "* Постройте график значения перплексии в зависимости от итерации (убедитесь в корректности реализации: график перплексии должен быть невозрастающим). \n",
    "* Выведите для каждой темы топ-20 наиболее вероятных слов.\n",
    "\n",
    "Посмотрите внимательно на полученные темы. Как вам кажется, получились ли они интерпретируемыми?"
   ]
  },
  {
   "cell_type": "code",
   "id": "efa99e9f",
   "metadata": {},
   "source": [
    "class PLSA:\n",
    "    def __init__(self, counts: np.matrix, T: int):\n",
    "        self.counts = counts\n",
    "        self.T = T\n",
    "\n",
    "        # your code here\n",
    "\n",
    "        initialize_params()\n",
    "\n",
    "    def initialize_params(self):\n",
    "        self.Phi =  # your code here\n",
    "        self.Theta =  # your code here\n",
    "\n",
    "    def step(self):\n",
    "\n",
    "    # your code here\n",
    "\n",
    "    def perplexity(self) -> float:\n",
    "\n",
    "# your code here"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "06918bea",
   "metadata": {},
   "source": [
    "**Задание 5 (1 балл)** \n",
    "\n",
    "Рассмотрите большее число тем (10, 20) и несколько различных начальных приближений. Проанализируйте результаты и ответьте на следующие вопросы: \n",
    "\n",
    "- Mожно ли сказать, что интерпретируемость каждой темы изменяется с ростом их числа?\n",
    "- Устойчив ли алгоритм к начальному приближению на примере идентичности топовых слов в соответствующих темах?\n",
    "- Отражает ли перплексия качество получаемых моделей? В чём заключается причина хорошего/плохого соответствия?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64c6265",
   "metadata": {},
   "source": [
    "## Кластеризация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a685dd0",
   "metadata": {},
   "source": [
    "**Задание 6 (2 балла)** \n",
    "\n",
    "В данном задание следуют сравнить между собой алгоритмы [KMeans](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html), [DBSCAN](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html) и [Birch](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.Birch.html) используя подготовленные ранее данные.\n",
    "\n",
    "Поэксперементируйте с различными способами векторизации текста, например можно:\n",
    "\n",
    "- использовать только *name* / *description*, объединить их в один текст или сконкатенировать векторные представления,\n",
    "- использовать представление в виде мешка слов или какую-либо его модификацию,\n",
    "- сократить размерность векторного представления, используя PCA или векторные представления слов,\n",
    "\n",
    "или сделать что-то более интересное, что вы придумаете!\n",
    "\n",
    "Выберете лучшую комбинацию векторизации и алгоритма кластеризации и визуализируйте полученные кластеры (например, воспользовавшись облаком тегов, или предложите свой способ). Обоснуйте почему вы считаете, что выбранный вами подход для решения задачи кластеризации вакансий является лучшим.\n",
    "\n",
    "**Задание \"со звездочкой\" (1 балл)** \n",
    "\n",
    "Попробуйте обогатить векторное представление полученное из текстов другими признаками из таблицы `vacancies.csv` и добиться лучшей интерпретируемости кластеров."
   ]
  },
  {
   "cell_type": "code",
   "id": "2a1828ff",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4c697e46",
   "metadata": {},
   "source": [
    "## Частичное обучение\n",
    "\n",
    "Часто у нас есть размеченная выборка только для небольшой части выборки. Тогда мы можем применить подходы _частичного обучения (semi-supervised learning)_. Более подробно про реализацию таких методов в sklearn можно прочитать в разделе [semi-supervised](http://scikit-learn.org/stable/modules/label_propagation.html#semi-supervised)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceffa132",
   "metadata": {},
   "source": [
    "**Задание 7 (2 балла)** \n",
    "\n",
    "В этом задание нужно сделать следующее: \n",
    "\n",
    "- Разделите объекты, у которых существуют метки, на обучающую и тестовую выборки (при этом не обязательно делить в соотношении 70% на 30%). Обогатите обучающую выборку объектами без меток.\n",
    "- Воспользовавшись опытом выполнения задания 6, возьмите \"лучшее\" векторное представление вакансий и обучите [LabelSpreading](http://scikit-learn.org/stable/modules/generated/sklearn.semi_supervised.LabelSpreading.html) (подберите лучшие параметры, опираясь на [F1 score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)).\n",
    "- Попробуйте запустить алгоритм несколько раз, отмечая известными различные объекты, а также меняя пропорции разбиения, посчитайте качество и визуализируйте результаты. Можно ли сказать что алгоритм сильно зависит от известных начальных объектов? Есть ли класс, для которого это больше всего заметно?"
   ]
  },
  {
   "cell_type": "code",
   "id": "f8e44914",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

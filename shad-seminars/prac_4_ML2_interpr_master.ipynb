{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d43fbba",
   "metadata": {
    "cellId": "6tgifddr0g4wmt8cy6lx7h"
   },
   "source": [
    "    # **Seminar 5 - Интерпретация Нейросетей**\n",
    "*Naumov Anton (Any0019)*\n",
    "\n",
    "*To contact me in telegram: @any0019*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d08d4a",
   "metadata": {
    "cellId": "l5w7dxjwy9qp98m1xhmr",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1. Почему мы любим PyTorch - Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba17b28",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7f6ac4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:20.919300Z",
     "start_time": "2024-03-05T17:41:20.916619Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3dca736",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:20.972816Z",
     "start_time": "2024-03-05T17:41:20.969187Z"
    },
    "cellId": "f9jjd2z227v9h6m63vmuyv",
    "execution": {
     "iopub.execute_input": "2024-03-05T10:40:06.797060Z",
     "iopub.status.busy": "2024-03-05T10:40:06.796138Z",
     "iopub.status.idle": "2024-03-05T10:40:06.857868Z",
     "shell.execute_reply": "2024-03-05T10:40:06.857186Z",
     "shell.execute_reply.started": "2024-03-05T10:40:06.797010Z"
    }
   },
   "outputs": [],
   "source": [
    "nn.Module?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1a74d0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:21.214136Z",
     "start_time": "2024-03-05T17:41:21.057561Z"
    },
    "cellId": "4jeetepwf0pxdy76c9ved",
    "execution": {
     "iopub.execute_input": "2024-03-05T10:40:09.573739Z",
     "iopub.status.busy": "2024-03-05T10:40:09.573040Z",
     "iopub.status.idle": "2024-03-05T10:40:09.790422Z",
     "shell.execute_reply": "2024-03-05T10:40:09.789354Z",
     "shell.execute_reply.started": "2024-03-05T10:40:09.573696Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nn.Module??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba275406",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:21.307955Z",
     "start_time": "2024-03-05T17:41:21.218695Z"
    }
   },
   "outputs": [],
   "source": [
    "torch??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62935346",
   "metadata": {
    "cellId": "on5wugrb2u7a0xbq0581v",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 1.1. Простой модуль"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f602f833",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:21.313083Z",
     "start_time": "2024-03-05T17:41:21.310143Z"
    },
    "cellId": "ovl50zog3yhq02zanfzyo",
    "execution": {
     "iopub.execute_input": "2024-03-05T10:42:21.406307Z",
     "iopub.status.busy": "2024-03-05T10:42:21.405189Z",
     "iopub.status.idle": "2024-03-05T10:42:21.430766Z",
     "shell.execute_reply": "2024-03-05T10:42:21.430053Z",
     "shell.execute_reply.started": "2024-03-05T10:42:21.406258Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        # Задаём через nn.Parameter, чтобы torch знал, что это обучаемые веса модуля\n",
    "        self.weight = nn.Parameter(torch.randn(in_features, out_features))\n",
    "        self.bias = nn.Parameter(torch.randn(out_features))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return (input @ self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fe129ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:21.349521Z",
     "start_time": "2024-03-05T17:41:21.314455Z"
    },
    "cellId": "mz5r3t4w83ddcr9ql36qx",
    "execution": {
     "iopub.execute_input": "2024-03-05T10:42:22.933575Z",
     "iopub.status.busy": "2024-03-05T10:42:22.932743Z",
     "iopub.status.idle": "2024-03-05T10:42:23.106444Z",
     "shell.execute_reply": "2024-03-05T10:42:23.105688Z",
     "shell.execute_reply.started": "2024-03-05T10:42:22.933521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.6166,  0.1872, -0.1115, -0.9617])\n",
      "tensor([ 0.4654, -0.6221,  3.5059], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "m = MyLinear(4, 3)\n",
    "sample_input = torch.randn(4)\n",
    "print(sample_input, m(sample_input), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de4f0bbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:21.353782Z",
     "start_time": "2024-03-05T17:41:21.350618Z"
    },
    "cellId": "3vern0sfsbmmme211whzj",
    "execution": {
     "iopub.execute_input": "2024-03-05T10:42:44.921891Z",
     "iopub.status.busy": "2024-03-05T10:42:44.921165Z",
     "iopub.status.idle": "2024-03-05T10:42:44.943631Z",
     "shell.execute_reply": "2024-03-05T10:42:44.942764Z",
     "shell.execute_reply.started": "2024-03-05T10:42:44.921846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name ~ 'weight'\n",
      "Parameter containing:\n",
      "tensor([[ 0.6940,  1.9101,  1.7811],\n",
      "        [ 0.7554,  1.1344, -0.2302],\n",
      "        [-1.1227, -1.2612,  0.1784],\n",
      "        [-0.5356,  0.4291, -1.5721]], requires_grad=True)\n",
      "-----\n",
      "Name ~ 'bias'\n",
      "Parameter containing:\n",
      "tensor([-0.7443, -1.7403,  0.9587], requires_grad=True)\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "for name, param in m.named_parameters():\n",
    "    print(f\"Name ~ '{name}'\", param, sep=\"\\n\", end=\"\\n-----\\n\")\n",
    "\n",
    "# # Аналогично, но только сами параметры, когда не нужны имена\n",
    "# for param in m.parameters():\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "611ccb71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:21.364987Z",
     "start_time": "2024-03-05T17:41:21.354688Z"
    },
    "cellId": "5ct89zwcvosomrgpdu4po",
    "execution": {
     "iopub.execute_input": "2024-03-05T10:42:53.577365Z",
     "iopub.status.busy": "2024-03-05T10:42:53.576542Z",
     "iopub.status.idle": "2024-03-05T10:42:53.610142Z",
     "shell.execute_reply": "2024-03-05T10:42:53.609345Z",
     "shell.execute_reply.started": "2024-03-05T10:42:53.577317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8257,  0.5732, -1.7226,  0.2652])\n",
      "tensor([0.7621], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential(\n",
    "  MyLinear(4, 3),\n",
    "  nn.ReLU(),\n",
    "  MyLinear(3, 1)\n",
    ")\n",
    "\n",
    "sample_input = torch.randn(4)\n",
    "print(sample_input, net(sample_input), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c7bbb3",
   "metadata": {
    "cellId": "b7cdrfjagtc73bv09ggw3m",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 1.2. Нейросеть с SubModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "893770e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:21.450537Z",
     "start_time": "2024-03-05T17:41:21.446827Z"
    },
    "cellId": "m9aysh7wdlkzylm4go16vp",
    "execution": {
     "iopub.execute_input": "2024-03-05T10:43:28.452230Z",
     "iopub.status.busy": "2024-03-05T10:43:28.451535Z",
     "iopub.status.idle": "2024-03-05T10:43:28.465561Z",
     "shell.execute_reply": "2024-03-05T10:43:28.464811Z",
     "shell.execute_reply.started": "2024-03-05T10:43:28.452188Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l0 = MyLinear(4, 3)\n",
    "        self.l1 = MyLinear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.l0(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.l1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1631622a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:21.590231Z",
     "start_time": "2024-03-05T17:41:21.586641Z"
    },
    "cellId": "65d60lw0r6cxn4sj810rj",
    "execution": {
     "iopub.execute_input": "2024-03-05T10:43:30.000314Z",
     "iopub.status.busy": "2024-03-05T10:43:29.999533Z",
     "iopub.status.idle": "2024-03-05T10:43:30.106916Z",
     "shell.execute_reply": "2024-03-05T10:43:30.106067Z",
     "shell.execute_reply.started": "2024-03-05T10:43:30.000267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name ~ 'l0'\n",
      "MyLinear()\n",
      "<generator object Module.parameters at 0x7ff2c7060350>\n",
      "-----\n",
      "Name ~ 'l1'\n",
      "MyLinear()\n",
      "<generator object Module.parameters at 0x7ff2c7060350>\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "for name, child in net.named_children():\n",
    "    print(f\"Name ~ '{name}'\", child, child.parameters(), sep=\"\\n\", end=\"\\n-----\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce29602b",
   "metadata": {
    "cellId": "xcs1i6hwhs9skl372hvqa",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 1.3. Сложная нейросеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ede97900",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:21.673423Z",
     "start_time": "2024-03-05T17:41:21.669076Z"
    },
    "cellId": "s0a1dpp7aeb2ugeuas6ve",
    "execution": {
     "iopub.execute_input": "2024-03-05T10:44:17.240633Z",
     "iopub.status.busy": "2024-03-05T10:44:17.239889Z",
     "iopub.status.idle": "2024-03-05T10:44:17.256253Z",
     "shell.execute_reply": "2024-03-05T10:44:17.255578Z",
     "shell.execute_reply.started": "2024-03-05T10:44:17.240597Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class BigNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = MyLinear(5, 4)\n",
    "        self.net = Net()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(self.l1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "769d6f81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:21.766614Z",
     "start_time": "2024-03-05T17:41:21.758982Z"
    },
    "cellId": "4meswezl58xhv264s9f8l",
    "execution": {
     "iopub.execute_input": "2024-03-05T10:44:19.209781Z",
     "iopub.status.busy": "2024-03-05T10:44:19.208900Z",
     "iopub.status.idle": "2024-03-05T10:44:19.228456Z",
     "shell.execute_reply": "2024-03-05T10:44:19.227753Z",
     "shell.execute_reply.started": "2024-03-05T10:44:19.209730Z"
    }
   },
   "outputs": [],
   "source": [
    "# pip install termcolor -- если не установлен пакет\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2753675e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:21.886319Z",
     "start_time": "2024-03-05T17:41:21.878086Z"
    }
   },
   "outputs": [],
   "source": [
    "colored??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8f8a0c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:21.971646Z",
     "start_time": "2024-03-05T17:41:21.966340Z"
    },
    "cellId": "wivfs9m1kmwcnrog4d4v",
    "execution": {
     "iopub.execute_input": "2024-03-05T10:44:20.839366Z",
     "iopub.status.busy": "2024-03-05T10:44:20.838718Z",
     "iopub.status.idle": "2024-03-05T10:44:20.862543Z",
     "shell.execute_reply": "2024-03-05T10:44:20.861856Z",
     "shell.execute_reply.started": "2024-03-05T10:44:20.839323Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[4m\u001B[1m\u001B[31mChildren:\n",
      "\u001B[0m\n",
      "Name ~ 'l1'\n",
      "MyLinear()\n",
      "-----\n",
      "Name ~ 'net'\n",
      "Net(\n",
      "  (l0): MyLinear()\n",
      "  (l1): MyLinear()\n",
      ")\n",
      "-----\n",
      "\n",
      "========\n",
      "\n",
      "\u001B[4m\u001B[1m\u001B[31mModules:\n",
      "\u001B[0m\n",
      "Name ~ ''\n",
      "BigNet(\n",
      "  (l1): MyLinear()\n",
      "  (net): Net(\n",
      "    (l0): MyLinear()\n",
      "    (l1): MyLinear()\n",
      "  )\n",
      ")\n",
      "-----\n",
      "Name ~ 'l1'\n",
      "MyLinear()\n",
      "-----\n",
      "Name ~ 'net'\n",
      "Net(\n",
      "  (l0): MyLinear()\n",
      "  (l1): MyLinear()\n",
      ")\n",
      "-----\n",
      "Name ~ 'net.l0'\n",
      "MyLinear()\n",
      "-----\n",
      "Name ~ 'net.l1'\n",
      "MyLinear()\n",
      "-----\n",
      "\n",
      "========\n",
      "\n",
      "\u001B[4m\u001B[1m\u001B[31mParameters:\n",
      "\u001B[0m\n",
      "Name ~ 'l1.weight'\n",
      "Parameter containing:\n",
      "tensor([[ 0.3335,  0.2650, -0.8692,  0.0452],\n",
      "        [ 0.8542, -0.3271, -1.8471,  1.3540],\n",
      "        [-0.9122, -0.2698,  0.4293, -0.2072],\n",
      "        [-1.7424,  0.7316, -1.6963,  0.9810],\n",
      "        [ 0.5721, -1.0295, -0.9624, -0.2203]], requires_grad=True)\n",
      "-----\n",
      "Name ~ 'l1.bias'\n",
      "Parameter containing:\n",
      "tensor([-0.2191, -0.9370, -0.6860, -0.4008], requires_grad=True)\n",
      "-----\n",
      "Name ~ 'net.l0.weight'\n",
      "Parameter containing:\n",
      "tensor([[-0.5887,  0.5767, -1.4264],\n",
      "        [-0.6210, -0.7664, -0.0511],\n",
      "        [-1.3368, -0.4219, -0.1066],\n",
      "        [ 0.2281, -0.4645,  0.1202]], requires_grad=True)\n",
      "-----\n",
      "Name ~ 'net.l0.bias'\n",
      "Parameter containing:\n",
      "tensor([-1.5881,  0.1059, -1.0054], requires_grad=True)\n",
      "-----\n",
      "Name ~ 'net.l1.weight'\n",
      "Parameter containing:\n",
      "tensor([[ 0.2208],\n",
      "        [-1.4381],\n",
      "        [ 1.3746]], requires_grad=True)\n",
      "-----\n",
      "Name ~ 'net.l1.bias'\n",
      "Parameter containing:\n",
      "tensor([1.0572], requires_grad=True)\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "big_net = BigNet()\n",
    "\n",
    "\n",
    "print(colored(\"Children:\\n\", color=\"red\", attrs=[\"bold\", \"underline\"]))\n",
    "for name, child in big_net.named_children():\n",
    "    print(f\"Name ~ '{name}'\", child, sep=\"\\n\", end=\"\\n-----\\n\")\n",
    "print(\"\\n========\\n\")\n",
    "\n",
    "\n",
    "print(colored(\"Modules:\\n\", color=\"red\", attrs=[\"bold\", \"underline\"]))\n",
    "for name, module in big_net.named_modules():\n",
    "    print(f\"Name ~ '{name}'\", module, sep=\"\\n\", end=\"\\n-----\\n\")\n",
    "print(\"\\n========\\n\")\n",
    "\n",
    "\n",
    "print(colored(\"Parameters:\\n\", color=\"red\", attrs=[\"bold\", \"underline\"]))\n",
    "for name, param in big_net.named_parameters():\n",
    "    print(f\"Name ~ '{name}'\", param, sep=\"\\n\", end=\"\\n-----\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac8f59a",
   "metadata": {
    "cellId": "temjuow8ns5u5obl9ls",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 1.4. Динамические модули"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f441be4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:22.078662Z",
     "start_time": "2024-03-05T17:41:22.071892Z"
    },
    "cellId": "huik6g0bqhspx9qogjxepn",
    "execution": {
     "iopub.execute_input": "2024-03-05T10:52:34.610481Z",
     "iopub.status.busy": "2024-03-05T10:52:34.609735Z",
     "iopub.status.idle": "2024-03-05T10:52:34.633226Z",
     "shell.execute_reply": "2024-03-05T10:52:34.632546Z",
     "shell.execute_reply.started": "2024-03-05T10:52:34.610430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3613,  0.8164, -0.3973,  0.4987])\n",
      "tensor([-1.9543], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class DynamicNet(nn.Module):\n",
    "    def __init__(self, num_layers):\n",
    "        super().__init__()\n",
    "        # nn.ModuleList - список модулей\n",
    "        self.linears = nn.ModuleList(\n",
    "            [MyLinear(4, 4) for _ in range(num_layers)]\n",
    "        )\n",
    "        # nn.ModuleDict - словарь модулей\n",
    "        self.activations = nn.ModuleDict({\n",
    "          \"relu\": nn.ReLU(),\n",
    "          \"lrelu\": nn.LeakyReLU()\n",
    "        })\n",
    "        self.final = MyLinear(4, 1)\n",
    "\n",
    "    def forward(self, x, act):\n",
    "        for linear in self.linears:\n",
    "            x = linear(x)\n",
    "        x = self.activations[act](x)\n",
    "        x = self.final(x)\n",
    "        return x\n",
    "\n",
    "dynamic_net = DynamicNet(3)\n",
    "sample_input = torch.randn(4)\n",
    "output = dynamic_net(sample_input, \"relu\")\n",
    "print(sample_input, output, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2ac890",
   "metadata": {
    "cellId": "ari5uhjtlcmckh0cnlld",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 1.5. Состояние модуля (train vs eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47991bc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:22.174554Z",
     "start_time": "2024-03-05T17:41:22.171357Z"
    },
    "cellId": "h0ufc2l73bpbtaocxad1fi",
    "execution": {
     "iopub.execute_input": "2024-03-05T10:52:45.727426Z",
     "iopub.status.busy": "2024-03-05T10:52:45.726600Z",
     "iopub.status.idle": "2024-03-05T10:52:45.746721Z",
     "shell.execute_reply": "2024-03-05T10:52:45.746031Z",
     "shell.execute_reply.started": "2024-03-05T10:52:45.727380Z"
    }
   },
   "outputs": [],
   "source": [
    "class ModalModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            # Добавляет константу, но только в .train() режиме\n",
    "            return x + 1.\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd2b57d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:22.246818Z",
     "start_time": "2024-03-05T17:41:22.241937Z"
    },
    "cellId": "o6hhpwcznmjtzbc3jxy99",
    "execution": {
     "iopub.execute_input": "2024-03-05T10:52:46.636087Z",
     "iopub.status.busy": "2024-03-05T10:52:46.635404Z",
     "iopub.status.idle": "2024-03-05T10:52:46.653730Z",
     "shell.execute_reply": "2024-03-05T10:52:46.652996Z",
     "shell.execute_reply.started": "2024-03-05T10:52:46.636042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "tensor([-0.3988,  0.8999, -0.5211,  2.0428])\n",
      "\n",
      "Training mode output:\n",
      "tensor([0.6012, 1.8999, 0.4789, 3.0428])\n",
      "\n",
      "Evaluation mode output:\n",
      "tensor([-0.3988,  0.8999, -0.5211,  2.0428])\n"
     ]
    }
   ],
   "source": [
    "m = ModalModule()\n",
    "x = torch.randn(4)\n",
    "\n",
    "print(f\"Input:\\n{x}\\n\")\n",
    "\n",
    "print(f\"Training mode output:\\n{m(x)}\\n\")\n",
    "\n",
    "m.eval()\n",
    "print(f\"Evaluation mode output:\\n{m(x)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024c1184",
   "metadata": {
    "cellId": "m453m9ejer5lpf2n8rxi",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 1.6. Тип данных и вычислений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f427cfb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:23.993320Z",
     "start_time": "2024-03-05T17:41:22.354399Z"
    },
    "cellId": "jns265fggpxhco9ftm7ob",
    "execution": {
     "iopub.execute_input": "2024-03-05T10:53:20.944170Z",
     "iopub.status.busy": "2024-03-05T10:53:20.943247Z",
     "iopub.status.idle": "2024-03-05T10:53:20.977780Z",
     "shell.execute_reply": "2024-03-05T10:53:20.977129Z",
     "shell.execute_reply.started": "2024-03-05T10:53:20.944137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3613,  0.8164, -0.3973,  0.4987], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "tensor([-1.9543], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "dtype = torch.float64\n",
    "\n",
    "# Переместить все параметры модели на device\n",
    "dynamic_net.to(device=device)\n",
    "# dynamic_net.cpu()\n",
    "# dynamic_net.cuda(int: ...)\n",
    "\n",
    "# Изменить тип всех параметров модели\n",
    "dynamic_net.to(dtype=dtype)\n",
    "# dynamic_net = dynamic_net.double()  # float64\n",
    "# dynamic_net = dynamic_net.float()  # float32\n",
    "# dynamic_net = dynamic_net.half() # float16\n",
    "\n",
    "sample_input = sample_input.to(device, dtype=dtype)\n",
    "\n",
    "output = dynamic_net(sample_input, \"relu\")\n",
    "\n",
    "print(sample_input, output, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d88013",
   "metadata": {
    "cellId": "ul91677dgsltlgcre4muq",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 1.7. Применение функций к модулям нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5c512df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:24.001441Z",
     "start_time": "2024-03-05T17:41:23.995020Z"
    },
    "cellId": "kkjq5djnl6xhvnb0oo3rf",
    "execution": {
     "iopub.execute_input": "2024-03-05T10:54:29.720951Z",
     "iopub.status.busy": "2024-03-05T10:54:29.720259Z",
     "iopub.status.idle": "2024-03-05T10:54:29.736704Z",
     "shell.execute_reply": "2024-03-05T10:54:29.736037Z",
     "shell.execute_reply.started": "2024-03-05T10:54:29.720907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DynamicNet(\n",
       "  (linears): ModuleList(\n",
       "    (0-2): 3 x MyLinear()\n",
       "  )\n",
       "  (activations): ModuleDict(\n",
       "    (relu): ReLU()\n",
       "    (lrelu): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (final): MyLinear()\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сделаем функцию для инициализации весов модели\n",
    "# обёртка no_grad() - используется тут, чтобы избежать подсчёта градиентов для этой операции\n",
    "@torch.no_grad()\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight, gain=1.0)  # см следующую ячейку\n",
    "        m.bias.fill_(0.0)\n",
    "\n",
    "# Применяем функцию рекурсивно ко всем модулям и подмодулям\n",
    "dynamic_net.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1600122",
   "metadata": {
    "cellId": "1hkzv4inuwa59afw3nkma5"
   },
   "source": [
    "Xavier / Glorot initialization\n",
    "\n",
    "`Understanding the difficulty of training deep feedforward neural networks` - Glorot, X. & Bengio, Y. (2010) ([ссылка](https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf))\n",
    "\n",
    "$$\\text{std} = \\text{gain} \\times \\sqrt{\\frac{2}{\\text{n}_{in} + \\text{n}_{out}}}$$\n",
    "\n",
    ", где $n_{in}$ и $n_{out}$ - число входов и выходов слоя соответственно\n",
    "\n",
    "Веса получаются следующим образом: $w \\sim \\mathcal{N}(0, std^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45195d0",
   "metadata": {
    "cellId": "ig2cces2h0c4iz4iucswl4",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 1.8. Сохранение и загрузка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "125fe04b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:24.012524Z",
     "start_time": "2024-03-05T17:41:24.002162Z"
    },
    "cellId": "0bxgsr02g6j2pmmc0xz6f7",
    "execution": {
     "iopub.execute_input": "2024-03-05T10:56:20.285713Z",
     "iopub.status.busy": "2024-03-05T10:56:20.284923Z",
     "iopub.status.idle": "2024-03-05T10:56:20.299429Z",
     "shell.execute_reply": "2024-03-05T10:56:20.298755Z",
     "shell.execute_reply.started": "2024-03-05T10:56:20.285659Z"
    }
   },
   "outputs": [],
   "source": [
    "big_net = BigNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89908d40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:24.031419Z",
     "start_time": "2024-03-05T17:41:24.013846Z"
    },
    "cellId": "81boht5siurulh6584ubnm",
    "execution": {
     "iopub.execute_input": "2024-03-05T10:56:21.511661Z",
     "iopub.status.busy": "2024-03-05T10:56:21.511028Z",
     "iopub.status.idle": "2024-03-05T10:56:21.535160Z",
     "shell.execute_reply": "2024-03-05T10:56:21.534418Z",
     "shell.execute_reply.started": "2024-03-05T10:56:21.511623Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('l1.weight',\n",
       "              tensor([[-0.0191,  1.2292,  0.1451, -0.9757],\n",
       "                      [-0.2225, -1.3176, -0.1401, -0.4058],\n",
       "                      [ 1.0882, -0.8344,  0.4885,  0.1290],\n",
       "                      [ 0.7019, -0.5358, -0.6567,  0.3075],\n",
       "                      [ 0.4647,  0.1682, -0.2453, -0.0396]])),\n",
       "             ('l1.bias', tensor([-0.8558,  0.0913, -1.6116, -1.6033])),\n",
       "             ('net.l0.weight',\n",
       "              tensor([[-0.1703,  0.0414,  0.1816],\n",
       "                      [ 0.0990, -0.7249,  1.3218],\n",
       "                      [-0.0451,  0.9671,  0.4000],\n",
       "                      [ 2.9454,  0.0156, -1.2182]])),\n",
       "             ('net.l0.bias', tensor([-1.3934, -0.4419,  0.1924])),\n",
       "             ('net.l1.weight',\n",
       "              tensor([[-0.4814],\n",
       "                      [-0.3640],\n",
       "                      [-1.5567]])),\n",
       "             ('net.l1.bias', tensor([-1.4237]))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Словарь со всеми весами модели\n",
    "big_net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2777b80c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:24.040186Z",
     "start_time": "2024-03-05T17:41:24.032529Z"
    },
    "cellId": "aqt99rmdjqbntai58e0y6",
    "execution": {
     "iopub.execute_input": "2024-03-05T10:56:33.704925Z",
     "iopub.status.busy": "2024-03-05T10:56:33.704258Z",
     "iopub.status.idle": "2024-03-05T10:56:33.722870Z",
     "shell.execute_reply": "2024-03-05T10:56:33.722177Z",
     "shell.execute_reply.started": "2024-03-05T10:56:33.704889Z"
    }
   },
   "outputs": [],
   "source": [
    "# Сохраняем state_dict нашей модели\n",
    "torch.save(\n",
    "    big_net.state_dict(),\n",
    "    \"net.pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8f2ebd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:24.057421Z",
     "start_time": "2024-03-05T17:41:24.041256Z"
    },
    "cellId": "215dowlsxnp3kh5gg0ajhd",
    "execution": {
     "iopub.execute_input": "2024-03-05T10:57:03.425619Z",
     "iopub.status.busy": "2024-03-05T10:57:03.424955Z",
     "iopub.status.idle": "2024-03-05T10:57:03.448430Z",
     "shell.execute_reply": "2024-03-05T10:57:03.447628Z",
     "shell.execute_reply.started": "2024-03-05T10:57:03.425576Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('l1.weight', tensor([[-0.0191,  1.2292,  0.1451, -0.9757],\n",
      "        [-0.2225, -1.3176, -0.1401, -0.4058],\n",
      "        [ 1.0882, -0.8344,  0.4885,  0.1290],\n",
      "        [ 0.7019, -0.5358, -0.6567,  0.3075],\n",
      "        [ 0.4647,  0.1682, -0.2453, -0.0396]])), ('l1.bias', tensor([-0.8558,  0.0913, -1.6116, -1.6033])), ('net.l0.weight', tensor([[-0.1703,  0.0414,  0.1816],\n",
      "        [ 0.0990, -0.7249,  1.3218],\n",
      "        [-0.0451,  0.9671,  0.4000],\n",
      "        [ 2.9454,  0.0156, -1.2182]])), ('net.l0.bias', tensor([-1.3934, -0.4419,  0.1924])), ('net.l1.weight', tensor([[-0.4814],\n",
      "        [-0.3640],\n",
      "        [-1.5567]])), ('net.l1.bias', tensor([-1.4237]))])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Инициализируем модель с таким же набором параметров\n",
    "new_big_net = BigNet()\n",
    "\n",
    "# Загружаем state_dict сохранённой модели в память\n",
    "state_dict = torch.load(\"net.pt\")\n",
    "print(state_dict)\n",
    "\n",
    "# Подгружаем state_dict в инициализированную модель\n",
    "new_big_net.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565f7904",
   "metadata": {
    "cellId": "b11cyq2n2bk3u440kax7g"
   },
   "source": [
    "**[Важно!] В общем случае - сохраняйте всю необходимую информацию о модели, оптимайзере, этапе обучения, ...**\n",
    "\n",
    "Best practice $\\longrightarrow$ подумайте, что вам будет нужно, если вы захотите, загрузив назад модель, продолжить её обучение:\n",
    "* обучаемые параметры\n",
    "* оптимизатор\n",
    "* шедулер\n",
    "* какие графики рисуете\n",
    "* на какой эпохе находитесь\n",
    "* ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65d6ee60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:24.061930Z",
     "start_time": "2024-03-05T17:41:24.058903Z"
    },
    "cellId": "3oytsj45hc8ewx1n782vs",
    "execution": {
     "iopub.execute_input": "2024-03-05T10:57:23.589737Z",
     "iopub.status.busy": "2024-03-05T10:57:23.588880Z",
     "iopub.status.idle": "2024-03-05T10:57:23.606826Z",
     "shell.execute_reply": "2024-03-05T10:57:23.605920Z",
     "shell.execute_reply.started": "2024-03-05T10:57:23.589687Z"
    }
   },
   "outputs": [],
   "source": [
    "# К примеру:\n",
    "\n",
    "# torch.save(\n",
    "#     {\n",
    "#         \"epoch\": epoch,\n",
    "#         \"model_state_dict\": model.state_dict(),\n",
    "#         \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "#         \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "#         \"losses\": losses,\n",
    "#     },\n",
    "#     chkp_path,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca58a00",
   "metadata": {
    "cellId": "4l322ztbi3x0r24z3i52x2",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 1.9. Буфферы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a4b2202",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:24.076235Z",
     "start_time": "2024-03-05T17:41:24.062870Z"
    },
    "cellId": "5pbf2ybdetb1ahpomjuomti",
    "execution": {
     "iopub.execute_input": "2024-03-05T10:58:44.880842Z",
     "iopub.status.busy": "2024-03-05T10:58:44.880186Z",
     "iopub.status.idle": "2024-03-05T10:58:44.899024Z",
     "shell.execute_reply": "2024-03-05T10:58:44.898317Z",
     "shell.execute_reply.started": "2024-03-05T10:58:44.880802Z"
    }
   },
   "outputs": [],
   "source": [
    "nn.Module.register_buffer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f8ca2e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:24.086990Z",
     "start_time": "2024-03-05T17:41:24.077197Z"
    },
    "cellId": "1mraymrxqyybq3ufquzi8",
    "execution": {
     "iopub.execute_input": "2024-03-05T10:59:27.142973Z",
     "iopub.status.busy": "2024-03-05T10:59:27.142243Z",
     "iopub.status.idle": "2024-03-05T10:59:27.153465Z",
     "shell.execute_reply": "2024-03-05T10:59:27.152667Z",
     "shell.execute_reply.started": "2024-03-05T10:59:27.142924Z"
    }
   },
   "outputs": [],
   "source": [
    "class RunningMean(nn.Module):\n",
    "    def __init__(self, num_features, momentum=0.9):\n",
    "        super().__init__()\n",
    "        self.momentum = momentum\n",
    "        # регистрируем буфер - параметр модели, но не обучаемый\n",
    "        self.register_buffer(\n",
    "            \"mean\",\n",
    "            torch.zeros(num_features),\n",
    "            persistent=True,  # содержится ли в state_dict модели?\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.mean = self.momentum * self.mean + (1.0 - self.momentum) * x\n",
    "        return self.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e22e4ac2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:24.102174Z",
     "start_time": "2024-03-05T17:41:24.089678Z"
    },
    "cellId": "qo7mjzw14v9c5on27b4jj",
    "execution": {
     "iopub.execute_input": "2024-03-05T10:59:28.545357Z",
     "iopub.status.busy": "2024-03-05T10:59:28.544701Z",
     "iopub.status.idle": "2024-03-05T10:59:28.569426Z",
     "shell.execute_reply": "2024-03-05T10:59:28.568516Z",
     "shell.execute_reply.started": "2024-03-05T10:59:28.545321Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('mean', tensor([-0.1285,  0.2087,  0.1013, -0.1055]))])\n"
     ]
    }
   ],
   "source": [
    "m = RunningMean(4)\n",
    "for _ in range(10):\n",
    "    input = torch.randn(4)\n",
    "    m(input)\n",
    "\n",
    "print(m.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "020acb2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:24.108724Z",
     "start_time": "2024-03-05T17:41:24.103781Z"
    },
    "cellId": "et16dtdrqbqsd6yoyn5hj",
    "execution": {
     "iopub.execute_input": "2024-03-05T10:59:42.497585Z",
     "iopub.status.busy": "2024-03-05T10:59:42.496746Z",
     "iopub.status.idle": "2024-03-05T10:59:42.514575Z",
     "shell.execute_reply": "2024-03-05T10:59:42.513748Z",
     "shell.execute_reply.started": "2024-03-05T10:59:42.497532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[4m\u001B[1m\u001B[31mParameters:\n",
      "\u001B[0m\n",
      "\n",
      "========\n",
      "\n",
      "\u001B[4m\u001B[1m\u001B[31mBuffers:\n",
      "\u001B[0m\n",
      "Name ~ 'mean'\n",
      "tensor([-0.1285,  0.2087,  0.1013, -0.1055])\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "print(colored(\"Parameters:\\n\", color=\"red\", attrs=[\"bold\", \"underline\"]))\n",
    "for name, param in m.named_parameters():\n",
    "    print(f\"Name ~ '{name}'\", param, sep=\"\\n\", end=\"\\n-----\\n\")\n",
    "print(\"\\n========\\n\")\n",
    "\n",
    "\n",
    "print(colored(\"Buffers:\\n\", color=\"red\", attrs=[\"bold\", \"underline\"]))\n",
    "for name, buffer in m.named_buffers():\n",
    "    print(f\"Name ~ '{name}'\", buffer, sep=\"\\n\", end=\"\\n-----\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ff830a",
   "metadata": {
    "cellId": "4ndizgv95ee5votyvlkmss",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 1.10. Инициализация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6b2cdc",
   "metadata": {
    "cellId": "9suw6do1f4guwucn0ueapn"
   },
   "source": [
    "Все параметры и floating point буфферы инициализируются на этапе инициализации модуля:\n",
    "* Тип ~ `param.float()` или `param.to(dtype=torch.float32)`.\n",
    "* Устройство ~ `param.cpu()`, или `param.to(\"cpu\")`, или `param.to(torch.device(\"cpu\"))`.\n",
    "* Инициализация значений ~ схема, соответствующая исторически предпочитаемой инициализацией для данного вида слоёв."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "121e43e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:24.164578Z",
     "start_time": "2024-03-05T17:41:24.109684Z"
    },
    "cellId": "q01tykyu6od3oy2pev87y",
    "execution": {
     "iopub.execute_input": "2024-03-05T11:00:53.731054Z",
     "iopub.status.busy": "2024-03-05T11:00:53.730027Z",
     "iopub.status.idle": "2024-03-05T11:00:53.814838Z",
     "shell.execute_reply": "2024-03-05T11:00:53.813900Z",
     "shell.execute_reply.started": "2024-03-05T11:00:53.730999Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.3452, -0.2675, -0.3891,  0.6214, -0.5214],\n",
       "        [-0.5010,  0.2199,  0.5922,  0.3344, -0.4879],\n",
       "        [ 0.6530, -0.0789,  0.6634,  0.2401,  0.2639]], requires_grad=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Инициализировать на другом устройстве сразу\n",
    "m = nn.Linear(5, 3, device='cuda')\n",
    "\n",
    "# Инициализировать другим типом данных сразу\n",
    "m = nn.Linear(5, 3, dtype=torch.half)\n",
    "\n",
    "# Пропустить стандартную инициализацию и провести кастомную (для примера ортогональную)\n",
    "m = nn.Linear(5, 3)\n",
    "nn.init.orthogonal_(m.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4289b3",
   "metadata": {
    "cellId": "ik2s13mmc2hu04kliaz6q",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2. Forward / Backward hooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1bc098",
   "metadata": {
    "cellId": "4aa7d4ota2p3zog5im4zyh"
   },
   "source": [
    "Hooks - способ взаимодействия с `torch.Tensor` и/или `nn.Module` для получения и модификации входов / выходов / градиентов в момент их прохода через forward / backward pass."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1116707c",
   "metadata": {
    "cellId": "ax511kucdw43nzylktgbfj",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 2.1. Module level hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4548a7da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:24.172888Z",
     "start_time": "2024-03-05T17:41:24.166511Z"
    },
    "cellId": "hvy27qbmpsegzemglzztgs",
    "execution": {
     "iopub.execute_input": "2024-03-05T11:01:14.454782Z",
     "iopub.status.busy": "2024-03-05T11:01:14.454230Z",
     "iopub.status.idle": "2024-03-05T11:01:14.472586Z",
     "shell.execute_reply": "2024-03-05T11:01:14.471886Z",
     "shell.execute_reply.started": "2024-03-05T11:01:14.454739Z"
    }
   },
   "outputs": [],
   "source": [
    "def forward_pre_hook(m, inputs):\n",
    "    # Исполняется перед выполнением forward на соответствующем элементе\n",
    "    # Может изменить входы в forward\n",
    "    print(\n",
    "        colored(\"Froward pre hook\", color=\"red\", attrs=[\"bold\", \"underline\"]),\n",
    "        inputs,\n",
    "        \" - Sizes ~ [\" + \", \".join([str(el.shape) for el in inputs if el is not None]) + \"]\",\n",
    "        sep=\"\\n\",\n",
    "        end=\"\\n\\n\",\n",
    "    )\n",
    "    return None  # None - не менять inputs, либо new_inputs\n",
    "\n",
    "def forward_hook(m, inputs, output):\n",
    "    # Исполняется после выполнения forward на соответствующем элементе\n",
    "    # Может изменить выход из forward\n",
    "    print(\n",
    "        colored(\"Froward hook\", color=\"red\", attrs=[\"bold\", \"underline\"]),\n",
    "        inputs,\n",
    "        \" - Sizes ~ [\" + \", \".join([str(el.shape) for el in inputs if el is not None]) + \"]\",\n",
    "        output,\n",
    "        f\" - Size ~ {output.shape}\",\n",
    "        sep=\"\\n\",\n",
    "        end=\"\\n\\n\",\n",
    "    )\n",
    "    return None  # None - не менять output, либо new_output\n",
    "\n",
    "def backward_hook(m, grad_inputs, grad_outputs):\n",
    "    # Исполняется после выполнения backward на соответствующем элементе\n",
    "    # Может изменить grad_inputs (выход на этапе backward)\n",
    "    print(\n",
    "        colored(\"Backward hook\", color=\"red\", attrs=[\"bold\", \"underline\"]),\n",
    "        grad_inputs,\n",
    "        \" - Sizes ~ [\" + \", \".join([str(el.shape) for el in grad_inputs if el is not None]) + \"]\",\n",
    "        grad_outputs,\n",
    "        \" - Sizes ~ [\" + \", \".join([str(el.shape) for el in grad_outputs if el is not None]) + \"]\",\n",
    "        sep=\"\\n\",\n",
    "        end=\"\\n\\n\",\n",
    "    )\n",
    "    return None  # None - не менять grad_inputs, либо new_grad_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e82960c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:24.187279Z",
     "start_time": "2024-03-05T17:41:24.173887Z"
    },
    "cellId": "80ml9tn5yf2jeg80arnxd",
    "execution": {
     "iopub.execute_input": "2024-03-05T11:03:57.128388Z",
     "iopub.status.busy": "2024-03-05T11:03:57.127647Z",
     "iopub.status.idle": "2024-03-05T11:03:57.139600Z",
     "shell.execute_reply": "2024-03-05T11:03:57.138857Z",
     "shell.execute_reply.started": "2024-03-05T11:03:57.128353Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "m = nn.Linear(4, 1)\n",
    "\n",
    "fp_handle = m.register_forward_pre_hook(forward_pre_hook)\n",
    "f_handle = m.register_forward_hook(forward_hook)\n",
    "# b_handle = m.register_backward_hook(backward_hook)  # --> deprecated\n",
    "b_handle = m.register_full_backward_hook(backward_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e3cdd306",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:24.206145Z",
     "start_time": "2024-03-05T17:41:24.188784Z"
    },
    "cellId": "re8jopt8ivhj2028agyf",
    "execution": {
     "iopub.execute_input": "2024-03-05T11:04:02.653919Z",
     "iopub.status.busy": "2024-03-05T11:04:02.653295Z",
     "iopub.status.idle": "2024-03-05T11:04:02.683142Z",
     "shell.execute_reply": "2024-03-05T11:04:02.682165Z",
     "shell.execute_reply.started": "2024-03-05T11:04:02.653877Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input\n",
      "tensor([[-1.1978e-01, -6.0965e-01, -6.3950e-01,  2.0342e+00],\n",
      "        [-7.7319e-04, -1.1496e+00,  1.3270e-01,  2.1189e-01],\n",
      "        [ 9.2858e-01, -8.7474e-02, -1.3829e+00, -6.6275e-01]],\n",
      "       requires_grad=True)\n",
      "\n",
      "\u001B[4m\u001B[1m\u001B[31mFroward pre hook\u001B[0m\n",
      "(tensor([[-1.1978e-01, -6.0965e-01, -6.3950e-01,  2.0342e+00],\n",
      "        [-7.7319e-04, -1.1496e+00,  1.3270e-01,  2.1189e-01],\n",
      "        [ 9.2858e-01, -8.7474e-02, -1.3829e+00, -6.6275e-01]],\n",
      "       requires_grad=True),)\n",
      " - Sizes ~ [torch.Size([3, 4])]\n",
      "\n",
      "\u001B[4m\u001B[1m\u001B[31mFroward hook\u001B[0m\n",
      "(tensor([[-1.1978e-01, -6.0965e-01, -6.3950e-01,  2.0342e+00],\n",
      "        [-7.7319e-04, -1.1496e+00,  1.3270e-01,  2.1189e-01],\n",
      "        [ 9.2858e-01, -8.7474e-02, -1.3829e+00, -6.6275e-01]],\n",
      "       grad_fn=<BackwardHookFunctionBackward>),)\n",
      " - Sizes ~ [torch.Size([3, 4])]\n",
      "tensor([[ 0.1004],\n",
      "        [ 0.4472],\n",
      "        [-0.5751]], grad_fn=<AddmmBackward0>)\n",
      " - Size ~ torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "sample_input = torch.randn(3, 4)\n",
    "sample_input.requires_grad = True\n",
    "\n",
    "print(\"Input\", sample_input, sep=\"\\n\", end=\"\\n\\n\")\n",
    "\n",
    "out = m(sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "74edc21e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:24.225608Z",
     "start_time": "2024-03-05T17:41:24.208281Z"
    },
    "cellId": "pw77676by9iplhn0fl5ngb",
    "execution": {
     "iopub.execute_input": "2024-03-05T11:04:08.077817Z",
     "iopub.status.busy": "2024-03-05T11:04:08.076947Z",
     "iopub.status.idle": "2024-03-05T11:04:08.101685Z",
     "shell.execute_reply": "2024-03-05T11:04:08.100939Z",
     "shell.execute_reply.started": "2024-03-05T11:04:08.077780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[4m\u001B[1m\u001B[31mBackward hook\u001B[0m\n",
      "(tensor([[-0.1339, -0.3703,  0.3090,  0.0416],\n",
      "        [-0.1339, -0.3703,  0.3090,  0.0416],\n",
      "        [-0.1339, -0.3703,  0.3090,  0.0416]]),)\n",
      " - Sizes ~ [torch.Size([3, 4])]\n",
      "(tensor([[1.],\n",
      "        [1.],\n",
      "        [1.]]),)\n",
      " - Sizes ~ [torch.Size([3, 1])]\n"
     ]
    }
   ],
   "source": [
    "out.backward(torch.ones_like(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "585b2505",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:24.230602Z",
     "start_time": "2024-03-05T17:41:24.227225Z"
    },
    "cellId": "t9g9kf4crlqbiehbmwoae",
    "execution": {
     "iopub.execute_input": "2024-03-05T11:04:15.999370Z",
     "iopub.status.busy": "2024-03-05T11:04:15.998584Z",
     "iopub.status.idle": "2024-03-05T11:04:16.046369Z",
     "shell.execute_reply": "2024-03-05T11:04:16.045638Z",
     "shell.execute_reply.started": "2024-03-05T11:04:15.999330Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fp_handle.remove()\n",
    "f_handle.remove()\n",
    "b_handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "54724acd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:24.243560Z",
     "start_time": "2024-03-05T17:41:24.232105Z"
    },
    "cellId": "5egwcjcbc0v3l71x1moebm",
    "execution": {
     "iopub.execute_input": "2024-03-05T11:04:18.760131Z",
     "iopub.status.busy": "2024-03-05T11:04:18.759476Z",
     "iopub.status.idle": "2024-03-05T11:04:18.790019Z",
     "shell.execute_reply": "2024-03-05T11:04:18.789275Z",
     "shell.execute_reply.started": "2024-03-05T11:04:18.760089Z"
    }
   },
   "outputs": [],
   "source": [
    "out = m(sample_input)\n",
    "out.backward(torch.ones_like(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c13511f",
   "metadata": {
    "cellId": "vm77vj22ogc3yi6eids56",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 2.2. Tensor level hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7fddbd59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:24.250893Z",
     "start_time": "2024-03-05T17:41:24.244542Z"
    },
    "cellId": "c8q9ql4gse4iog277696u",
    "execution": {
     "iopub.execute_input": "2024-03-05T11:04:59.452568Z",
     "iopub.status.busy": "2024-03-05T11:04:59.451838Z",
     "iopub.status.idle": "2024-03-05T11:04:59.463233Z",
     "shell.execute_reply": "2024-03-05T11:04:59.462559Z",
     "shell.execute_reply.started": "2024-03-05T11:04:59.452528Z"
    }
   },
   "outputs": [],
   "source": [
    "def tensor_hook(grad):\n",
    "    print(\n",
    "        colored(\"Tensor backward hook\", color=\"red\", attrs=[\"bold\", \"underline\"]),\n",
    "        grad,\n",
    "        f\" - Size ~ {grad.shape}\",\n",
    "        sep=\"\\n\",\n",
    "        end=\"\\n\\n\",\n",
    "    )\n",
    "    return None  # None - не менять grad, либо new_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3c7cc7b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:24.262293Z",
     "start_time": "2024-03-05T17:41:24.251916Z"
    },
    "cellId": "mx4v7mojyacdqtpct6yrue",
    "execution": {
     "iopub.execute_input": "2024-03-05T11:05:00.170677Z",
     "iopub.status.busy": "2024-03-05T11:05:00.169664Z",
     "iopub.status.idle": "2024-03-05T11:05:00.260775Z",
     "shell.execute_reply": "2024-03-05T11:05:00.259992Z",
     "shell.execute_reply.started": "2024-03-05T11:05:00.170607Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "m = nn.Linear(4, 1)\n",
    "\n",
    "w_t_handle = m.weight.register_hook(tensor_hook)\n",
    "b_t_handle = m.bias.register_hook(tensor_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "112424e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:24.274881Z",
     "start_time": "2024-03-05T17:41:24.263375Z"
    },
    "cellId": "glyki87smfnoqefva8lgp",
    "execution": {
     "iopub.execute_input": "2024-03-05T11:05:01.994064Z",
     "iopub.status.busy": "2024-03-05T11:05:01.993331Z",
     "iopub.status.idle": "2024-03-05T11:05:02.062957Z",
     "shell.execute_reply": "2024-03-05T11:05:02.062089Z",
     "shell.execute_reply.started": "2024-03-05T11:05:01.994018Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input\n",
      "tensor([[-0.6002,  0.7938, -0.7718, -0.9000],\n",
      "        [-1.3973, -2.7942,  1.2243, -0.5767],\n",
      "        [-0.7879, -1.3380,  0.6665, -1.8168]], requires_grad=True)\n",
      "\n",
      "\u001B[4m\u001B[1m\u001B[31mTensor backward hook\u001B[0m\n",
      "tensor([3.])\n",
      " - Size ~ torch.Size([1])\n",
      "\n",
      "\u001B[4m\u001B[1m\u001B[31mTensor backward hook\u001B[0m\n",
      "tensor([[-2.7854, -3.3383,  1.1190, -3.2936]])\n",
      " - Size ~ torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "sample_input = torch.randn(3, 4)\n",
    "sample_input.requires_grad = True\n",
    "\n",
    "print(\"Input\", sample_input, sep=\"\\n\", end=\"\\n\\n\")\n",
    "\n",
    "out = m(sample_input)\n",
    "out.backward(torch.ones_like(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dfddf80c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:24.285351Z",
     "start_time": "2024-03-05T17:41:24.275684Z"
    },
    "cellId": "oqbcnz4sqykl9wxtdeha5",
    "execution": {
     "iopub.execute_input": "2024-03-05T11:05:04.796847Z",
     "iopub.status.busy": "2024-03-05T11:05:04.796106Z",
     "iopub.status.idle": "2024-03-05T11:05:04.811026Z",
     "shell.execute_reply": "2024-03-05T11:05:04.810159Z",
     "shell.execute_reply.started": "2024-03-05T11:05:04.796799Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3.]), tensor([[-2.7854, -3.3383,  1.1190, -3.2936]]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.bias.grad, m.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "583599b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:24.294734Z",
     "start_time": "2024-03-05T17:41:24.286280Z"
    },
    "cellId": "o4fs425bzj6fgnwijyblk",
    "execution": {
     "iopub.execute_input": "2024-03-05T11:05:07.991672Z",
     "iopub.status.busy": "2024-03-05T11:05:07.990627Z",
     "iopub.status.idle": "2024-03-05T11:05:08.015201Z",
     "shell.execute_reply": "2024-03-05T11:05:08.014372Z",
     "shell.execute_reply.started": "2024-03-05T11:05:07.991625Z"
    }
   },
   "outputs": [],
   "source": [
    "w_t_handle.remove()\n",
    "b_t_handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ee236810",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:41:24.305576Z",
     "start_time": "2024-03-05T17:41:24.296817Z"
    },
    "cellId": "nodfs0h6byoz70kffh8c",
    "execution": {
     "iopub.execute_input": "2024-03-05T11:05:08.962766Z",
     "iopub.status.busy": "2024-03-05T11:05:08.961980Z",
     "iopub.status.idle": "2024-03-05T11:05:08.974695Z",
     "shell.execute_reply": "2024-03-05T11:05:08.973897Z",
     "shell.execute_reply.started": "2024-03-05T11:05:08.962729Z"
    }
   },
   "outputs": [],
   "source": [
    "out = m(sample_input)\n",
    "out.backward(torch.ones_like(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2743371",
   "metadata": {
    "cellId": "afhq5928ak35blpalf5ih",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 2.3. Как достать и сохранить что-то из модели?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d69021f",
   "metadata": {
    "cellId": "yd7vwyhqztli6chonahvj"
   },
   "source": [
    "```python\n",
    "from collections import defaultdict\n",
    "\n",
    "hook_data = defaultdict(list)\n",
    "\n",
    "def hook(*args):\n",
    "    # берём из global scope-а перменную, созданную раньше\n",
    "    global hook_data\n",
    "    \n",
    "    ...\n",
    "    for key, value in ...:\n",
    "        hook_data[key].append(value)\n",
    "    \n",
    "    return None\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696bd3fd",
   "metadata": {
    "cellId": "tpebeirzklnx3lb32ibr5n"
   },
   "source": [
    "## 3. Интерпретация нейросетей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f7bc03",
   "metadata": {
    "cellId": "xet08a7tqbpoj5e3f6u22r"
   },
   "source": [
    "Главный вопрос интерпретации - **почему нейросеть повела себя так, как повела?**\n",
    "\n",
    "* Почему ответ был именно такой в конкретном случае?\n",
    "* Что нужно подать на вход, чтобы получить подобный ответ?\n",
    "* На что сильнее всего смотрит нейросеть, принимая решение?\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b9d9e0",
   "metadata": {
    "cellId": "sc2p7e905bgil8mol7q05k"
   },
   "source": [
    "Все стандартные подходы интерпретации из классического ML так же будут работать и с нейросетями (рассматривая нейросеть как функцию от входов как отдельных переменных), но при этом многие из них часто ориентированы на рассмотрение важности одной или нескольких фичей, а в случае с нейросетями часто входы будут иметь тысячи или даже миллионы фичей на входе (к пр., картинка 1920 x 1080 x 3 пикселей), что выйдет не очень хорошо:\n",
    "* значимость одной фичи маленькая\n",
    "* виды данных имеют свои особенности и зависимости\n",
    "* виды моделей имеют свои подходы к их анализу\n",
    "\n",
    "Сегодня мы будем рассматривать подходы для анализа нейросетей (на примере свёрточных нейросетей), подходы глобально можно разделить на группы по нескольким признакам:\n",
    "1. Анализ данных и зоны видимости при активации нейросетей\n",
    "2. Attribution - изучаем какая часть входа(ов) отвечает за активацию нейросети\n",
    "3. Feature visualization - подбираем изображения, наиболее соответствующие ожиданиям нейросети"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa08b0cf",
   "metadata": {
    "cellId": "qozee9gnttg1rwhbmryeos",
    "tags": []
   },
   "source": [
    "### 3.1. Подготовим модель и данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c956097d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:47:12.797672Z",
     "start_time": "2024-03-05T17:41:24.306510Z"
    },
    "cellId": "mbzyiamevf9kt2peixxl8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision==0.14.0\r\n",
      "  Downloading torchvision-0.14.0-cp310-cp310-manylinux1_x86_64.whl (24.3 MB)\r\n",
      "\u001B[2K     \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m24.3/24.3 MB\u001B[0m \u001B[31m6.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0mm eta \u001B[36m0:00:01\u001B[0m[36m0:00:01\u001B[0mm\r\n",
      "\u001B[?25hRequirement already satisfied: numpy in ./.local/lib/python3.10/site-packages (from torchvision==0.14.0) (1.26.0)\r\n",
      "Requirement already satisfied: requests in ./.local/lib/python3.10/site-packages (from torchvision==0.14.0) (2.26.0)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/lib/python3/dist-packages (from torchvision==0.14.0) (9.0.1)\r\n",
      "Collecting torch==1.13.0\r\n",
      "  Downloading torch-1.13.0-cp310-cp310-manylinux1_x86_64.whl (890.1 MB)\r\n",
      "\u001B[2K     \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m890.1/890.1 MB\u001B[0m \u001B[31m1.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0mm eta \u001B[36m0:00:01\u001B[0m[36m0:00:04\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: typing-extensions in ./.local/lib/python3.10/site-packages (from torchvision==0.14.0) (4.8.0)\r\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99\r\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\r\n",
      "\u001B[2K     \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m849.3/849.3 KB\u001B[0m \u001B[31m3.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m[31m4.2 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cublas-cu11==11.10.3.66\r\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\r\n",
      "\u001B[2K     \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m317.1/317.1 MB\u001B[0m \u001B[31m2.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0mm eta \u001B[36m0:00:01\u001B[0m[36m0:00:02\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\r\n",
      "\u001B[2K     \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m21.0/21.0 MB\u001B[0m \u001B[31m5.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0mm eta \u001B[36m0:00:01\u001B[0m[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\r\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\r\n",
      "\u001B[2K     \u001B[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[38;2;249;38;114m╸\u001B[0m\u001B[38;5;237m━━━━━\u001B[0m \u001B[32m481.0/557.1 MB\u001B[0m \u001B[31m6.2 MB/s\u001B[0m eta \u001B[36m0:00:13\u001B[0m^C\r\n",
      "\u001B[2K     \u001B[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[38;2;249;38;114m╸\u001B[0m\u001B[38;5;237m━━━━━\u001B[0m \u001B[32m481.1/557.1 MB\u001B[0m \u001B[31m6.1 MB/s\u001B[0m eta \u001B[36m0:00:13\u001B[0m\r\n",
      "\u001B[?25h\u001B[31mERROR: Operation cancelled by user\u001B[0m\u001B[31m\r\n",
      "\u001B[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade torchvision==0.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "283513ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:57:22.393658Z",
     "start_time": "2024-03-05T17:57:22.390118Z"
    },
    "cellId": "yw6e14qwwiew9iw5gt9znh",
    "execution": {
     "iopub.execute_input": "2024-03-05T11:07:41.481249Z",
     "iopub.status.busy": "2024-03-05T11:07:41.480563Z",
     "iopub.status.idle": "2024-03-05T11:07:42.937425Z",
     "shell.execute_reply": "2024-03-05T11:07:42.936639Z",
     "shell.execute_reply.started": "2024-03-05T11:07:41.481207Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2457506178.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[27], line 4\u001B[0;36m\u001B[0m\n\u001B[0;31m    python3.12 --version\u001B[0m\n\u001B[0m           ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from mpmath.libmp.backend import python3\n",
    "\n",
    "#!:bash\n",
    "python3 --version\n",
    "python3.12 -c \"import torchvision; import torch; print(f'torch ~ {torch.__version__}\\ntorchvision ~ {torchvision.__version__}')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cdbf91ac",
   "metadata": {
    "cellId": "f9to2hazsr87h3a1lu3hl4",
    "execution": {
     "iopub.execute_input": "2024-03-05T12:05:35.285416Z",
     "iopub.status.busy": "2024-03-05T12:05:35.284671Z",
     "iopub.status.idle": "2024-03-05T12:05:49.372923Z",
     "shell.execute_reply": "2024-03-05T12:05:49.371423Z",
     "shell.execute_reply.started": "2024-03-05T12:05:35.285363Z"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-03-05T17:58:12.276269Z",
     "start_time": "2024-03-05T17:58:11.862401Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Only a single TORCH_LIBRARY can be used to register the namespace triton; please put all of your definitions in a single TORCH_LIBRARY block.  If you were trying to specify implementations, consider using TORCH_LIBRARY_IMPL (which can be duplicated).  If you really intended to define operators for a single namespace in a distributed way, you can use TORCH_LIBRARY_FRAGMENT to explicitly indicate this.  Previous registration of TORCH_LIBRARY was registered at /dev/null:1880; latest registration was registered at /dev/null:1880",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[51], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mimportlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m reload\n\u001B[0;32m----> 5\u001B[0m \u001B[43mreload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m reload(torchvision)\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(torch\u001B[38;5;241m.\u001B[39m__version__, torchvision\u001B[38;5;241m.\u001B[39m__version__, sep\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/usr/lib/python3.10/importlib/__init__.py:169\u001B[0m, in \u001B[0;36mreload\u001B[0;34m(module)\u001B[0m\n\u001B[1;32m    167\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m spec \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    168\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mModuleNotFoundError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mspec not found for the module \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, name\u001B[38;5;241m=\u001B[39mname)\n\u001B[0;32m--> 169\u001B[0m \u001B[43m_bootstrap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_exec\u001B[49m\u001B[43m(\u001B[49m\u001B[43mspec\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodule\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    170\u001B[0m \u001B[38;5;66;03m# The module may have replaced itself in sys.modules!\u001B[39;00m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m sys\u001B[38;5;241m.\u001B[39mmodules[name]\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:619\u001B[0m, in \u001B[0;36m_exec\u001B[0;34m(spec, module)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap_external>:883\u001B[0m, in \u001B[0;36mexec_module\u001B[0;34m(self, module)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:241\u001B[0m, in \u001B[0;36m_call_with_frames_removed\u001B[0;34m(f, *args, **kwds)\u001B[0m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/torch/__init__.py:1880\u001B[0m\n\u001B[1;32m   1877\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _running_with_deploy():\n\u001B[1;32m   1878\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m compiler \u001B[38;5;28;01mas\u001B[39;00m compiler\n\u001B[0;32m-> 1880\u001B[0m     \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01m_TritonLibrary\u001B[39;00m:\n\u001B[1;32m   1881\u001B[0m         lib \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mlibrary\u001B[38;5;241m.\u001B[39mLibrary(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtriton\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDEF\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1882\u001B[0m         ops_table: Dict[Tuple[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mstr\u001B[39m], Callable] \u001B[38;5;241m=\u001B[39m {}\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/torch/__init__.py:1881\u001B[0m, in \u001B[0;36m_TritonLibrary\u001B[0;34m()\u001B[0m\n\u001B[1;32m   1880\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01m_TritonLibrary\u001B[39;00m:\n\u001B[0;32m-> 1881\u001B[0m     lib \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlibrary\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mLibrary\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtriton\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mDEF\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1882\u001B[0m     ops_table: Dict[Tuple[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mstr\u001B[39m], Callable] \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m   1884\u001B[0m     \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m   1885\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mregisterOp\u001B[39m(\u001B[38;5;28mcls\u001B[39m, op_key, full_schema, op_impl, dispatch_key):\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/torch/library.py:63\u001B[0m, in \u001B[0;36mLibrary.__init__\u001B[0;34m(self, ns, kind, dispatch_key)\u001B[0m\n\u001B[1;32m     61\u001B[0m frame \u001B[38;5;241m=\u001B[39m traceback\u001B[38;5;241m.\u001B[39mextract_stack(limit\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m)[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     62\u001B[0m filename, lineno \u001B[38;5;241m=\u001B[39m frame\u001B[38;5;241m.\u001B[39mfilename, frame\u001B[38;5;241m.\u001B[39mlineno\n\u001B[0;32m---> 63\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mm: Optional[Any] \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dispatch_library\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkind\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdispatch_key\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlineno\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mns \u001B[38;5;241m=\u001B[39m ns\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_op_defs: Set[\u001B[38;5;28mstr\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Only a single TORCH_LIBRARY can be used to register the namespace triton; please put all of your definitions in a single TORCH_LIBRARY block.  If you were trying to specify implementations, consider using TORCH_LIBRARY_IMPL (which can be duplicated).  If you really intended to define operators for a single namespace in a distributed way, you can use TORCH_LIBRARY_FRAGMENT to explicitly indicate this.  Previous registration of TORCH_LIBRARY was registered at /dev/null:1880; latest registration was registered at /dev/null:1880"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from importlib import reload\n",
    "reload(torch)\n",
    "reload(torchvision)\n",
    "print(torch.__version__, torchvision.__version__, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0a7cab",
   "metadata": {
    "cellId": "h4m0bo0crcvzqui88hapk",
    "execution": {
     "iopub.execute_input": "2024-03-05T12:07:13.503093Z",
     "iopub.status.busy": "2024-03-05T12:07:13.502312Z",
     "iopub.status.idle": "2024-03-05T12:07:13.518835Z",
     "shell.execute_reply": "2024-03-05T12:07:13.517439Z",
     "shell.execute_reply.started": "2024-03-05T12:07:13.503055Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca25b409",
   "metadata": {
    "cellId": "au8fhz1xpguq4swidjxi8",
    "execution": {
     "iopub.execute_input": "2024-03-05T12:07:14.957086Z",
     "iopub.status.busy": "2024-03-05T12:07:14.956242Z",
     "iopub.status.idle": "2024-03-05T12:09:02.874871Z",
     "shell.execute_reply": "2024-03-05T12:09:02.873620Z",
     "shell.execute_reply.started": "2024-03-05T12:07:14.957047Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_path = \"../Sem3 - DL tricks/data\"\n",
    "original_train_ds = datasets.STL10(root=dataset_path, split=\"train\", download=True)\n",
    "original_val_ds = datasets.STL10(root=dataset_path, split=\"test\", download=True)\n",
    "classes = original_train_ds.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41719656",
   "metadata": {
    "cellId": "fjdf49gcfj0wadgy18cdxl",
    "execution": {
     "iopub.execute_input": "2024-03-05T12:09:02.877779Z",
     "iopub.status.busy": "2024-03-05T12:09:02.876666Z",
     "iopub.status.idle": "2024-03-05T12:09:05.877158Z",
     "shell.execute_reply": "2024-03-05T12:09:05.875357Z",
     "shell.execute_reply.started": "2024-03-05T12:09:02.877710Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "h = 4\n",
    "w = 8\n",
    "fig, ax = plt.subplots(h, w, figsize=(30, 15))\n",
    "\n",
    "fig.suptitle(f\"all classes ~ [{', '.join(classes)}]\", y=0.85 + 0.02*h)\n",
    "for i in range(h * w):\n",
    "    plt.subplot(h, w, i+1)\n",
    "    img, cl = original_train_ds[i]\n",
    "    plt.imshow(img)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(f\"{cl} ~ {classes[cl]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833565bb",
   "metadata": {
    "cellId": "a8n5p3i6anctg1katmyntn",
    "execution": {
     "iopub.execute_input": "2024-03-05T12:10:14.964040Z",
     "iopub.status.busy": "2024-03-05T12:10:14.962748Z",
     "iopub.status.idle": "2024-03-05T12:10:15.281772Z",
     "shell.execute_reply": "2024-03-05T12:10:15.280406Z",
     "shell.execute_reply.started": "2024-03-05T12:10:14.964000Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from torch import nn\n",
    "\n",
    "def get_model_and_transforms():\n",
    "    weights = models.ResNet18_Weights.DEFAULT\n",
    "    model = models.resnet18(weights=weights, progress=True)\n",
    "\n",
    "    # замораживаем первые слои\n",
    "    for name, param in model.named_parameters():\n",
    "        if not name.startswith(\"layer4\"):\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # заменяем классификатор\n",
    "    model.fc = nn.Linear(model.fc.in_features, len(classes))\n",
    "\n",
    "    transforms = weights.transforms()\n",
    "    \n",
    "    return model, transforms\n",
    "\n",
    "model, transforms = get_model_and_transforms()\n",
    "\n",
    "print(model, transforms, sep=\"\\n=========\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8741b452",
   "metadata": {
    "cellId": "23922ul551akvuyjrf5w",
    "execution": {
     "iopub.execute_input": "2024-03-05T12:11:28.219050Z",
     "iopub.status.busy": "2024-03-05T12:11:28.217755Z",
     "iopub.status.idle": "2024-03-05T12:11:28.281139Z",
     "shell.execute_reply": "2024-03-05T12:11:28.279771Z",
     "shell.execute_reply.started": "2024-03-05T12:11:28.219006Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from termcolor import colored\n",
    "\n",
    "def beautiful_int(i):\n",
    "    i = str(i)\n",
    "    return \".\".join(reversed([i[max(j, 0):j+3] for j in range(len(i) - 3, -3, -3)]))\n",
    "\n",
    "# Counting how many parameters does our model have\n",
    "def model_num_params(model, verbose_all=True, verbose_only_learnable=False):\n",
    "    sum_params = 0\n",
    "    sum_learnable_params = 0\n",
    "    for param in model.named_parameters():\n",
    "        num_params = np.prod(param[1].shape)\n",
    "        if verbose_all or (verbose_only_learnable and param[1].requires_grad):\n",
    "            print(\n",
    "                colored(\n",
    "                    '{: <42} ~  {: <9} params ~ grad: {}'.format(\n",
    "                        param[0],\n",
    "                        beautiful_int(num_params),\n",
    "                        param[1].requires_grad,\n",
    "                    ),\n",
    "                    {True: \"green\", False: \"red\"}[param[1].requires_grad],\n",
    "                )\n",
    "            )\n",
    "        sum_params += num_params\n",
    "        if param[1].requires_grad:\n",
    "            sum_learnable_params += num_params\n",
    "    print(\n",
    "        f'\\nIn total:\\n  - {beautiful_int(sum_params)} params\\n  - {beautiful_int(sum_learnable_params)} learnable params'\n",
    "    )\n",
    "    return sum_params, sum_learnable_params\n",
    "\n",
    "\n",
    "sum_params, sum_learnable_params = model_num_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8eb09c",
   "metadata": {
    "cellId": "38ok2p0hlyti1rb5c1hs6f",
    "execution": {
     "iopub.execute_input": "2024-03-05T12:12:03.568687Z",
     "iopub.status.busy": "2024-03-05T12:12:03.567666Z",
     "iopub.status.idle": "2024-03-05T12:12:03.597313Z",
     "shell.execute_reply": "2024-03-05T12:12:03.596171Z",
     "shell.execute_reply.started": "2024-03-05T12:12:03.568629Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms as tr\n",
    "\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "train_transform = tr.Compose([\n",
    "    tr.Resize(size=(256, 256)),\n",
    "    tr.RandomRotation(degrees=(-10, 10)),\n",
    "    tr.RandomCrop(size=(224, 224)),\n",
    "    tr.RandomHorizontalFlip(),\n",
    "    tr.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 0.5)),\n",
    "    tr.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "    tr.ToTensor(),\n",
    "    tr.Normalize(mean=mean, std=std),\n",
    "])\n",
    "\n",
    "val_transform = torchvision.transforms.Compose([\n",
    "    tr.Resize(size=(224, 224)),\n",
    "    tr.ToTensor(),\n",
    "    tr.Normalize(mean=mean, std=std),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4aad68",
   "metadata": {
    "cellId": "vy9ndyi9z2ov2138tbciec",
    "execution": {
     "iopub.execute_input": "2024-03-05T12:12:04.128890Z",
     "iopub.status.busy": "2024-03-05T12:12:04.127258Z",
     "iopub.status.idle": "2024-03-05T12:12:04.810051Z",
     "shell.execute_reply": "2024-03-05T12:12:04.808866Z",
     "shell.execute_reply.started": "2024-03-05T12:12:04.128827Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def de_normalize(img):\n",
    "    img = img.detach().numpy().transpose((1, 2, 0))\n",
    "    return img * std + mean\n",
    "\n",
    "\n",
    "img_ind = 0\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20, 7))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.imshow(original_train_ds[img_ind][0])\n",
    "plt.title(\"Before\")\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(de_normalize(train_transform(original_train_ds[img_ind][0])))\n",
    "plt.title(\"After train transform\")\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(de_normalize(val_transform(original_train_ds[img_ind][0])))\n",
    "plt.title(\"After val transform\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed643fc",
   "metadata": {
    "cellId": "k8cm20d0vp6u5shce4xyj",
    "execution": {
     "iopub.execute_input": "2024-03-05T12:12:11.922713Z",
     "iopub.status.busy": "2024-03-05T12:12:11.921666Z",
     "iopub.status.idle": "2024-03-05T12:12:11.939631Z",
     "shell.execute_reply": "2024-03-05T12:12:11.938413Z",
     "shell.execute_reply.started": "2024-03-05T12:12:11.922676Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, dataset, transforms):\n",
    "        super(ImageDataset).__init__()\n",
    "        self.dataset = dataset\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, cl = self.dataset[index]\n",
    "        return self.transforms(img), cl\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb5d1ff",
   "metadata": {
    "cellId": "8tby4fygnm8rrdlihmf97",
    "execution": {
     "iopub.execute_input": "2024-03-05T12:12:12.953413Z",
     "iopub.status.busy": "2024-03-05T12:12:12.952247Z",
     "iopub.status.idle": "2024-03-05T12:12:12.975605Z",
     "shell.execute_reply": "2024-03-05T12:12:12.974390Z",
     "shell.execute_reply.started": "2024-03-05T12:12:12.953359Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds = ImageDataset(original_train_ds, train_transform)\n",
    "val_ds = ImageDataset(original_val_ds, val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc4027a-3ae8-4b4c-b1cb-8b04d32c47fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T12:12:15.821216Z",
     "iopub.status.busy": "2024-03-05T12:12:15.820155Z",
     "iopub.status.idle": "2024-03-05T12:12:15.837137Z",
     "shell.execute_reply": "2024-03-05T12:12:15.835748Z",
     "shell.execute_reply.started": "2024-03-05T12:12:15.821171Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(train_ds), len(val_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921ae736",
   "metadata": {
    "cellId": "lprqppkx9sabj159c17do",
    "execution": {
     "iopub.execute_input": "2024-03-05T12:12:17.474358Z",
     "iopub.status.busy": "2024-03-05T12:12:17.473413Z",
     "iopub.status.idle": "2024-03-05T12:12:17.491603Z",
     "shell.execute_reply": "2024-03-05T12:12:17.490416Z",
     "shell.execute_reply.started": "2024-03-05T12:12:17.474318Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6459efd7",
   "metadata": {
    "cellId": "pob9xuigppfq3s9js1ter",
    "tags": []
   },
   "source": [
    "### 3.2. Дообучим модельку на задачу классификации STL10 датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cd479d",
   "metadata": {
    "cellId": "ocm6v5t9j8sh5dzjl2m88e",
    "execution": {
     "iopub.execute_input": "2024-03-05T12:12:20.176090Z",
     "iopub.status.busy": "2024-03-05T12:12:20.174919Z",
     "iopub.status.idle": "2024-03-05T12:12:20.216035Z",
     "shell.execute_reply": "2024-03-05T12:12:20.214821Z",
     "shell.execute_reply.started": "2024-03-05T12:12:20.176047Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "def create_model_and_optimizer(lr=1e-3, beta1=0.9, beta2=0.999, device=\"cpu\"):\n",
    "    model, _ = get_model_and_transforms()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    params = []\n",
    "    for param in model.parameters():\n",
    "        if param.requires_grad:\n",
    "            params.append(param)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(params, lr, [beta1, beta2])\n",
    "    return model, optimizer\n",
    "\n",
    "\n",
    "def train(model, optimizer, loader, criterion):\n",
    "    model.train()\n",
    "    losses_tr = []\n",
    "    for images, targets in tqdm(loader):\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out = model(images)\n",
    "        loss = criterion(out, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses_tr.append(loss.item()) \n",
    "    \n",
    "    return model, optimizer, np.mean(losses_tr)\n",
    "\n",
    "\n",
    "def val(model, loader, criterion, metric_names=None):\n",
    "    model.eval()\n",
    "    losses_val = []\n",
    "    if metric_names:\n",
    "        metrics = {name: [] for name in metric_names}\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(loader):\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            out = model(images)\n",
    "            loss = criterion(out, targets)\n",
    "            losses_val.append(loss.item())\n",
    "            \n",
    "            if metric_names:\n",
    "                if 'accuracy' in metrics:\n",
    "                    _, pred_classes = torch.max(out, dim=-1)\n",
    "                    metrics['accuracy'].append((pred_classes == targets).float().mean().item())\n",
    "                if 'top2accuracy' in metrics:\n",
    "                    preds = torch.argsort(out, dim=1, descending=True)\n",
    "                    metrics['top2accuracy'].append(\n",
    "                        np.mean([targets[i] in preds[i, :2] for i in range(len(targets))])\n",
    "                    )\n",
    "                if 'top3accuracy' in metrics:\n",
    "                    preds = torch.argsort(out, dim=1, descending=True)\n",
    "                    metrics['top3accuracy'].append(\n",
    "                        np.mean([targets[i] in preds[i, :3] for i in range(len(targets))])\n",
    "                    )\n",
    "    \n",
    "        if metric_names:\n",
    "            for name in metrics:\n",
    "                metrics[name] = np.mean(metrics[name])\n",
    "    \n",
    "    return np.mean(losses_val), metrics if metric_names else None\n",
    "\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "    \n",
    "\n",
    "def learning_loop(model, optimizer, train_loader, val_loader, criterion, scheduler=None, min_lr=None, epochs=10, val_every=1, draw_every=1, metric_names=None):\n",
    "    losses = {'train': [], 'val': []}\n",
    "    lrs = []\n",
    "    if metric_names:\n",
    "        metrics = {name: [] for name in metric_names}\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        print(f'#{epoch}/{epochs}:')\n",
    "        model, optimizer, loss = train(model, optimizer, train_loader, criterion)\n",
    "        losses['train'].append(loss)\n",
    "\n",
    "        if not (epoch % val_every):\n",
    "            loss, metrics_ = val(model, val_loader, criterion, metric_names)\n",
    "            losses['val'].append(loss)\n",
    "            if metric_names:\n",
    "                for name in metrics_:\n",
    "                    metrics[name].append(metrics_[name])\n",
    "            \n",
    "            lrs.append(get_lr(optimizer))\n",
    "            if scheduler:\n",
    "                try:\n",
    "                    scheduler.step()\n",
    "                except:\n",
    "                    scheduler.step(loss)\n",
    "\n",
    "        if not (epoch % draw_every):\n",
    "            clear_output(True)\n",
    "            ww = 3 if metric_names else 2\n",
    "            fig, ax = plt.subplots(1, ww, figsize=(20, 10))\n",
    "            fig.suptitle(f'#{epoch}/{epochs}:')\n",
    "\n",
    "            plt.subplot(1, ww, 1)\n",
    "            plt.title('losses')\n",
    "            plt.plot(losses['train'], 'r.-', label='train')\n",
    "            plt.plot(losses['val'], 'g.-', label='val')\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.subplot(1, ww, 2)\n",
    "            plt.title('learning rate')\n",
    "            plt.plot(lrs, '.-', label='lr')\n",
    "            plt.legend()\n",
    "            \n",
    "            if metric_names:\n",
    "                plt.subplot(1, ww, 3)\n",
    "                plt.title('additional metrics')\n",
    "                for name in metric_names:\n",
    "                    plt.plot(metrics[name], '.-', label=name)\n",
    "                plt.legend()\n",
    "            \n",
    "            plt.show()\n",
    "        \n",
    "        if min_lr and get_lr(optimizer) <= min_lr:\n",
    "            print(f'Learning process ended with early stop after epoch {epoch}')\n",
    "            break\n",
    "    \n",
    "    return model, optimizer, losses, lrs, metrics if metric_names else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3adcd0e",
   "metadata": {
    "cellId": "44v3i8spl9vn5dkieezy",
    "execution": {
     "iopub.execute_input": "2024-03-05T12:14:23.915574Z",
     "iopub.status.busy": "2024-03-05T12:14:23.914486Z",
     "iopub.status.idle": "2024-03-05T12:57:12.412222Z",
     "shell.execute_reply": "2024-03-05T12:57:12.410867Z",
     "shell.execute_reply.started": "2024-03-05T12:14:23.915528Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "NUM_EPOCHS = 30\n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model, optimizer = create_model_and_optimizer(\n",
    "    lr = 1e-4,\n",
    "    device = device,\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, NUM_EPOCHS, eta_min=1e-6)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model, optimizer, losses, lrs, metrics = learning_loop(\n",
    "    model = model,\n",
    "    optimizer = optimizer,\n",
    "    train_loader = train_loader,\n",
    "    val_loader = val_loader,\n",
    "    criterion = criterion,\n",
    "    scheduler = scheduler,\n",
    "    epochs = NUM_EPOCHS,\n",
    "    min_lr = None,\n",
    "    metric_names = {'accuracy', 'top3accuracy'},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd215f56",
   "metadata": {
    "cellId": "004jpbtz696xa4y904wdtzwc",
    "execution": {
     "iopub.execute_input": "2024-03-05T12:57:12.415434Z",
     "iopub.status.busy": "2024-03-05T12:57:12.414360Z",
     "iopub.status.idle": "2024-03-05T12:57:13.131989Z",
     "shell.execute_reply": "2024-03-05T12:57:13.130521Z",
     "shell.execute_reply.started": "2024-03-05T12:57:12.415377Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "chkp_path = \"./model.pt\"\n",
    "\n",
    "# Save\n",
    "torch.save(\n",
    "    {\n",
    "        'epoch': NUM_EPOCHS,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'losses': losses,\n",
    "    },\n",
    "    chkp_path,\n",
    ")\n",
    "\n",
    "\n",
    "# Load\n",
    "# checkpoint = torch.load(chkp_path)\n",
    "\n",
    "# model, optimizer = create_model_and_optimizer(\n",
    "#     lr = 1e-4,\n",
    "#     device = device,\n",
    "# )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, NUM_EPOCHS, eta_min=1e-6)\n",
    "\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "# epoch = checkpoint['epoch']\n",
    "# losses = checkpoint['losses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a877fac1",
   "metadata": {
    "cellId": "i298eowszrjzt8y4gxnj1k",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:02:52.896146Z",
     "iopub.status.busy": "2024-03-05T13:02:52.895243Z",
     "iopub.status.idle": "2024-03-05T13:02:52.917791Z",
     "shell.execute_reply": "2024-03-05T13:02:52.916348Z",
     "shell.execute_reply.started": "2024-03-05T13:02:52.896106Z"
    }
   },
   "outputs": [],
   "source": [
    "def real_confusion_matrix(model, val_loader, class_labels, use_probs=False, normalize=True, round_size=4):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        n_classes = len(class_labels)\n",
    "        conf_matrix = np.zeros((n_classes, n_classes))\n",
    "        for i, (img, cl) in enumerate(tqdm(val_loader)):\n",
    "            probs = model(img.to(device)).exp()\n",
    "            if use_probs:\n",
    "                for j in range(img.shape[0]):\n",
    "                    for c in range(n_classes):\n",
    "                        conf_matrix[cl[j].item(), c] += probs[j,c]\n",
    "            else:\n",
    "                _, pred_classes = torch.max(probs, 1)\n",
    "                for j in range(img.shape[0]):\n",
    "                    conf_matrix[cl[j].item(), pred_classes[j].item()] += 1.\n",
    "        \n",
    "        if normalize:\n",
    "            conf_matrix /= conf_matrix.sum(1)\n",
    "        \n",
    "        fig = plt.figure(figsize=(18, 10))\n",
    "        fig.suptitle(f'Confusion matrix (norm={normalize}, use_probs={use_probs})')\n",
    "        ax = fig.add_subplot(111)\n",
    "        cax = ax.matshow(conf_matrix.T)\n",
    "        fig.colorbar(cax)\n",
    "        \n",
    "        @plt.FuncFormatter\n",
    "        def fake_labels(x, pos):\n",
    "            return class_labels[(int(x))] if x < len(class_labels) else \"@\"\n",
    "        \n",
    "        ax.xaxis.set_ticks(list(range(len(class_labels))))\n",
    "        ax.xaxis.set_ticklabels(class_labels)\n",
    "        ax.set_xlabel('predicted class')\n",
    "        \n",
    "        ax.yaxis.set_ticks(list(range(len(class_labels))))\n",
    "        ax.yaxis.set_ticklabels(class_labels)\n",
    "        ax.set_ylabel('true class')\n",
    "        \n",
    "        for x in range(conf_matrix.shape[0]):\n",
    "            for y in range(conf_matrix.shape[1]):\n",
    "                ax.text(x, y, round(conf_matrix[x,y], round_size), va='center', ha='center')\n",
    "        \n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        return conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cecc6df",
   "metadata": {
    "cellId": "ogmxqfz36s7q6aoa9h90j",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:02:54.612317Z",
     "iopub.status.busy": "2024-03-05T13:02:54.611590Z",
     "iopub.status.idle": "2024-03-05T13:03:17.086797Z",
     "shell.execute_reply": "2024-03-05T13:03:17.085404Z",
     "shell.execute_reply.started": "2024-03-05T13:02:54.612259Z"
    }
   },
   "outputs": [],
   "source": [
    "pcm = real_confusion_matrix(\n",
    "    model,\n",
    "    val_loader,\n",
    "    classes,\n",
    "    use_probs=True,\n",
    "    normalize=True,\n",
    "    round_size=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364b3016",
   "metadata": {
    "cellId": "5dqltn6o2547ifj673ng6n",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:03:17.089502Z",
     "iopub.status.busy": "2024-03-05T13:03:17.088673Z",
     "iopub.status.idle": "2024-03-05T13:03:34.775840Z",
     "shell.execute_reply": "2024-03-05T13:03:34.774519Z",
     "shell.execute_reply.started": "2024-03-05T13:03:17.089446Z"
    }
   },
   "outputs": [],
   "source": [
    "pcm = real_confusion_matrix(\n",
    "    model,\n",
    "    val_loader,\n",
    "    classes,\n",
    "    use_probs=False,\n",
    "    normalize=True,\n",
    "    round_size=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2f48b5",
   "metadata": {
    "cellId": "w4i7atq6zi1uw2h5ljcr9"
   },
   "source": [
    "### 3.3. Что видит каждый слой нейросети?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a62810e",
   "metadata": {
    "cellId": "8t0orwro835m0bu11lu2"
   },
   "source": [
    "Посмотрим как *примерно* выглядят входы каждого соответствующего слоя нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8038cb53",
   "metadata": {
    "cellId": "vhz7qhsw0nqw26994ut7a"
   },
   "outputs": [],
   "source": [
    "# # Убрать hooks без handle:\n",
    "# from collections import OrderedDict\n",
    "# from typing import Dict, Callable\n",
    "\n",
    "# module._forward_hooks: Dict[int, Callable] = OrderedDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1042f667",
   "metadata": {
    "cellId": "zq746n48dvl29dx46cj3aq",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:21:47.513348Z",
     "iopub.status.busy": "2024-03-05T13:21:47.512400Z",
     "iopub.status.idle": "2024-03-05T13:21:47.833344Z",
     "shell.execute_reply": "2024-03-05T13:21:47.832073Z",
     "shell.execute_reply.started": "2024-03-05T13:21:47.513294Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_inputs = []\n",
    "handles = []\n",
    "\n",
    "def extract_input_pre_hook(m, inputs):\n",
    "    global layer_inputs\n",
    "    layer_inputs.append([m, inputs[0]])\n",
    "    return None\n",
    "\n",
    "conv_layers = []\n",
    "model = model.to(\"cpu\")\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, nn.Conv2d):\n",
    "        if \"downsample\" not in name:\n",
    "            conv_layers.append(module)\n",
    "            handles.append(module.register_forward_pre_hook(extract_input_pre_hook))\n",
    "    elif isinstance(module, (nn.MaxPool2d, nn.AvgPool2d)):\n",
    "        conv_layers.append(module)\n",
    "        handles.append(module.register_forward_pre_hook(extract_input_pre_hook))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a049db",
   "metadata": {
    "cellId": "1sho9ws50oelrarwzhkzz",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:21:48.320897Z",
     "iopub.status.busy": "2024-03-05T13:21:48.319806Z",
     "iopub.status.idle": "2024-03-05T13:21:48.347604Z",
     "shell.execute_reply": "2024-03-05T13:21:48.346376Z",
     "shell.execute_reply.started": "2024-03-05T13:21:48.320854Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "conv_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3425ac",
   "metadata": {
    "cellId": "1ig72r3zh27gzksfmco7cj",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:21:49.117005Z",
     "iopub.status.busy": "2024-03-05T13:21:49.116048Z",
     "iopub.status.idle": "2024-03-05T13:21:49.318804Z",
     "shell.execute_reply": "2024-03-05T13:21:49.317684Z",
     "shell.execute_reply.started": "2024-03-05T13:21:49.116961Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def min_max_scale(img):\n",
    "    img = img - img.min()\n",
    "    return img / img.max()\n",
    "\n",
    "img_ind = 4\n",
    "\n",
    "img = val_ds[img_ind][0]\n",
    "plt.imshow(min_max_scale(de_normalize(img)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceec79fb",
   "metadata": {
    "cellId": "sciuu0oy52kdpwt2yjmnp9",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:21:50.530947Z",
     "iopub.status.busy": "2024-03-05T13:21:50.530201Z",
     "iopub.status.idle": "2024-03-05T13:21:54.027515Z",
     "shell.execute_reply": "2024-03-05T13:21:54.026290Z",
     "shell.execute_reply.started": "2024-03-05T13:21:50.530890Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_hw(s):\n",
    "    h = int(np.round(np.sqrt(s)))\n",
    "    w = s // h + (s % h > 0)\n",
    "    return h, w\n",
    "\n",
    "h, w = get_hw(conv_layers[0].weight.shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(35, 35))\n",
    "fig.suptitle(\"Layer 1 kernels\", y=0.9)\n",
    "for i, kernel in enumerate(conv_layers[0].weight):\n",
    "    plt.subplot(h, w, i + 1)\n",
    "    plt.imshow(\n",
    "        min_max_scale(\n",
    "            kernel.detach().numpy().transpose(1, 2, 0)\n",
    "        )\n",
    "    )\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8108dcc7",
   "metadata": {
    "cellId": "u6c3m2zvs5o70r990g0eb",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:21:54.030600Z",
     "iopub.status.busy": "2024-03-05T13:21:54.029727Z",
     "iopub.status.idle": "2024-03-05T13:21:54.074588Z",
     "shell.execute_reply": "2024-03-05T13:21:54.073333Z",
     "shell.execute_reply.started": "2024-03-05T13:21:54.030542Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "out = model(img[None, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341cb004",
   "metadata": {
    "cellId": "wfpwum3g7pkxtd72kuzeeo",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:21:57.984387Z",
     "iopub.status.busy": "2024-03-05T13:21:57.983441Z",
     "iopub.status.idle": "2024-03-05T13:21:57.998147Z",
     "shell.execute_reply": "2024-03-05T13:21:57.996870Z",
     "shell.execute_reply.started": "2024-03-05T13:21:57.984342Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for handle in handles:\n",
    "    handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e315983",
   "metadata": {
    "cellId": "2d6bm7lauepqu1oihcyvvs",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:21:59.532769Z",
     "iopub.status.busy": "2024-03-05T13:21:59.531371Z",
     "iopub.status.idle": "2024-03-05T13:21:59.590214Z",
     "shell.execute_reply": "2024-03-05T13:21:59.589020Z",
     "shell.execute_reply.started": "2024-03-05T13:21:59.532704Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    fmaps = [conv_layers[0](img.unsqueeze(0))]\n",
    "    for module in conv_layers[1:]:\n",
    "        fmaps.append(module(fmaps[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c13024",
   "metadata": {
    "cellId": "ptz9w35o2bcy884tdp1to",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:22:00.621577Z",
     "iopub.status.busy": "2024-03-05T13:22:00.620466Z",
     "iopub.status.idle": "2024-03-05T13:22:00.656386Z",
     "shell.execute_reply": "2024-03-05T13:22:00.655112Z",
     "shell.execute_reply.started": "2024-03-05T13:22:00.621532Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_layer_fmap(fmaps, layer_ind, show_first=None, h=None):\n",
    "    actual = isinstance(fmaps[layer_ind], list)\n",
    "    if actual:\n",
    "        fmap = fmaps[layer_ind+1][1][0]\n",
    "    else:\n",
    "        fmap = fmaps[layer_ind][0]\n",
    "    s = show_first or fmap.shape[0]\n",
    "    \n",
    "    if h is None:\n",
    "        h, w = get_hw(s)\n",
    "    else:\n",
    "        w = s // h + (s % h > 0)\n",
    "    fig, ax = plt.subplots(h, w, figsize=(w * 5, h * 5))\n",
    "    fig.suptitle(f\"Layer #{layer_ind} {'actual' if actual else 'approximate'} feature maps\", y=0.9)\n",
    "    i = 1\n",
    "    for fmap_img in fmap:\n",
    "        if show_first and i > show_first:\n",
    "            break\n",
    "        if fmap_img.sum() == 0:\n",
    "            continue\n",
    "        plt.subplot(h, w, i)\n",
    "        plt.imshow(\n",
    "            min_max_scale(fmap_img.detach()),\n",
    "            cmap=\"gray\",\n",
    "        )\n",
    "        plt.axis('off')\n",
    "        i += 1\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b178db86",
   "metadata": {
    "cellId": "abxn7gktp7ie7bpfrixz",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:22:05.611923Z",
     "iopub.status.busy": "2024-03-05T13:22:05.610947Z",
     "iopub.status.idle": "2024-03-05T13:22:06.642314Z",
     "shell.execute_reply": "2024-03-05T13:22:06.641112Z",
     "shell.execute_reply.started": "2024-03-05T13:22:05.611883Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_layer_fmap(fmaps, 0, show_first=10, h=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1a862f",
   "metadata": {
    "cellId": "nrbkbrnlunsdfo9nlqugld",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:22:06.807632Z",
     "iopub.status.busy": "2024-03-05T13:22:06.806644Z",
     "iopub.status.idle": "2024-03-05T13:22:07.773520Z",
     "shell.execute_reply": "2024-03-05T13:22:07.772276Z",
     "shell.execute_reply.started": "2024-03-05T13:22:06.807584Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_layer_fmap(layer_inputs, 0, show_first=10, h=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e246c7e3",
   "metadata": {
    "cellId": "wl3nos2yv7a8gqnll3oduh",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:22:08.462461Z",
     "iopub.status.busy": "2024-03-05T13:22:08.461416Z",
     "iopub.status.idle": "2024-03-05T13:22:09.527350Z",
     "shell.execute_reply": "2024-03-05T13:22:09.525973Z",
     "shell.execute_reply.started": "2024-03-05T13:22:08.462404Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_layer_fmap(fmaps, 5, show_first=10, h=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47e5b66",
   "metadata": {
    "cellId": "1wr06v37vsb83hwrwfr7mu",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:22:10.658637Z",
     "iopub.status.busy": "2024-03-05T13:22:10.657646Z",
     "iopub.status.idle": "2024-03-05T13:22:11.470020Z",
     "shell.execute_reply": "2024-03-05T13:22:11.468777Z",
     "shell.execute_reply.started": "2024-03-05T13:22:10.658586Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_layer_fmap(layer_inputs, 5, show_first=10, h=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e959448c",
   "metadata": {
    "cellId": "7t4mtiwon3kg7kfccmdskv",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:22:11.514115Z",
     "iopub.status.busy": "2024-03-05T13:22:11.513284Z",
     "iopub.status.idle": "2024-03-05T13:22:12.318998Z",
     "shell.execute_reply": "2024-03-05T13:22:12.317837Z",
     "shell.execute_reply.started": "2024-03-05T13:22:11.514061Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_layer_fmap(fmaps, 10, show_first=10, h=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213d8251",
   "metadata": {
    "cellId": "3fr6g9vo254lkj6nhyk8l",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:22:12.362773Z",
     "iopub.status.busy": "2024-03-05T13:22:12.362190Z",
     "iopub.status.idle": "2024-03-05T13:22:13.438983Z",
     "shell.execute_reply": "2024-03-05T13:22:13.437847Z",
     "shell.execute_reply.started": "2024-03-05T13:22:12.362728Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_layer_fmap(layer_inputs, 10, show_first=10, h=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5820f5eb",
   "metadata": {
    "cellId": "cav80sl4ptb90nzz9im8mq"
   },
   "source": [
    "Не слишком информативно, хотя и даёт понимание о сложности интерпретации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221f7294",
   "metadata": {
    "cellId": "mgi9e8z66al5ihn2j7sdms"
   },
   "source": [
    "### 3.3. Анализ относительно датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40af368",
   "metadata": {
    "cellId": "ijvxqry4ue88rnwmct7rt2"
   },
   "source": [
    "#### 3.3.1. Картинки, сильнее всего активирующиеся на фичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0e65a6",
   "metadata": {
    "cellId": "65bbj98zrpj9sppprv40dg",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:22:43.415892Z",
     "iopub.status.busy": "2024-03-05T13:22:43.414777Z",
     "iopub.status.idle": "2024-03-05T13:23:01.017136Z",
     "shell.execute_reply": "2024-03-05T13:23:01.015788Z",
     "shell.execute_reply.started": "2024-03-05T13:22:43.415839Z"
    }
   },
   "outputs": [],
   "source": [
    "val_preds = []\n",
    "val_conv_activations = []\n",
    "val_pre_fc_preds = []\n",
    "targets = []\n",
    "\n",
    "def extract_input_hook(m, inputs, output):\n",
    "    val_conv_activations.append(inputs[0].cpu().detach().numpy())\n",
    "    val_pre_fc_preds.append(output.cpu().detach().numpy())\n",
    "    return None\n",
    "\n",
    "handle = model.avgpool.register_forward_hook(extract_input_hook)\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    for img, cl in tqdm(val_loader):\n",
    "        out = model(img.to(device))\n",
    "        val_preds.append(out.cpu().detach().numpy())\n",
    "        targets.append(cl.cpu().detach().numpy())\n",
    "model.cpu()\n",
    "\n",
    "val_preds = np.concatenate(val_preds, axis=0)\n",
    "val_pre_fc_preds = np.concatenate(val_pre_fc_preds, axis=0)\n",
    "val_conv_activations = np.concatenate(val_conv_activations, axis=0)\n",
    "targets = np.concatenate(targets, axis=0)\n",
    "\n",
    "handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dc7fef",
   "metadata": {
    "cellId": "igp7jqzzxtsdtr7pw1bc",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:24:26.068015Z",
     "iopub.status.busy": "2024-03-05T13:24:26.067062Z",
     "iopub.status.idle": "2024-03-05T13:24:26.085080Z",
     "shell.execute_reply": "2024-03-05T13:24:26.083752Z",
     "shell.execute_reply.started": "2024-03-05T13:24:26.067968Z"
    }
   },
   "outputs": [],
   "source": [
    "val_preds.shape, val_pre_fc_preds.shape, val_conv_activations.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5691711",
   "metadata": {
    "cellId": "z6smogg0fvusfs0sei1oe",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:24:52.412819Z",
     "iopub.status.busy": "2024-03-05T13:24:52.411644Z",
     "iopub.status.idle": "2024-03-05T13:24:52.438308Z",
     "shell.execute_reply": "2024-03-05T13:24:52.437030Z",
     "shell.execute_reply.started": "2024-03-05T13:24:52.412761Z"
    }
   },
   "outputs": [],
   "source": [
    "cl_to_ind = {cl: i for i, cl in enumerate(classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382eae58",
   "metadata": {
    "cellId": "n6lmq394uijzrj0h6d29g",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:25:13.548659Z",
     "iopub.status.busy": "2024-03-05T13:25:13.547684Z",
     "iopub.status.idle": "2024-03-05T13:25:13.567015Z",
     "shell.execute_reply": "2024-03-05T13:25:13.565863Z",
     "shell.execute_reply.started": "2024-03-05T13:25:13.548604Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_class = \"cat\"\n",
    "ind = cl_to_ind[selected_class]\n",
    "\n",
    "mask = (targets == ind).astype(bool)\n",
    "pre_fc_weights = model.fc.weight.detach().numpy()[ind, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99274b9c",
   "metadata": {
    "cellId": "qzetsdi76dh9yqrf4jcpb",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:26:06.817948Z",
     "iopub.status.busy": "2024-03-05T13:26:06.816918Z",
     "iopub.status.idle": "2024-03-05T13:26:07.013306Z",
     "shell.execute_reply": "2024-03-05T13:26:07.012023Z",
     "shell.execute_reply.started": "2024-03-05T13:26:06.817904Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25, 5))\n",
    "plt.plot(pre_fc_weights)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0016e975",
   "metadata": {
    "cellId": "r7cagj85sn8i0p11updjc",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:26:38.792682Z",
     "iopub.status.busy": "2024-03-05T13:26:38.791579Z",
     "iopub.status.idle": "2024-03-05T13:26:38.811642Z",
     "shell.execute_reply": "2024-03-05T13:26:38.810530Z",
     "shell.execute_reply.started": "2024-03-05T13:26:38.792639Z"
    }
   },
   "outputs": [],
   "source": [
    "select_top = 4\n",
    "best_features = np.argsort(-pre_fc_weights)\n",
    "worst_features = best_features[-select_top:]\n",
    "best_features = best_features[:select_top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d37f44",
   "metadata": {
    "cellId": "dmdj0peunqs23p3151fung",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:26:39.762159Z",
     "iopub.status.busy": "2024-03-05T13:26:39.761102Z",
     "iopub.status.idle": "2024-03-05T13:26:46.597115Z",
     "shell.execute_reply": "2024-03-05T13:26:46.595853Z",
     "shell.execute_reply.started": "2024-03-05T13:26:39.762103Z"
    }
   },
   "outputs": [],
   "source": [
    "show_top = 5\n",
    "\n",
    "fig, ax = plt.subplots(select_top * 2, show_top, figsize=(25, 10 * select_top))\n",
    "\n",
    "for i, feature_ind in enumerate(best_features):\n",
    "    best_img_inds = np.argsort(-val_pre_fc_preds[:, feature_ind, 0, 0])[:show_top]\n",
    "    for j, img_ind in enumerate(best_img_inds):\n",
    "        plt.subplot(select_top * 2, show_top, i * show_top + j + 1)\n",
    "        plt.imshow(original_val_ds[img_ind][0])\n",
    "        plt.title(f\"Top #{i+1} best feature\\nTop #{j+1} best image\")\n",
    "\n",
    "for i, feature_ind in enumerate(worst_features):\n",
    "    worst_img_inds = np.argsort(-val_pre_fc_preds[:, feature_ind, 0, 0])[:show_top]\n",
    "    for j, img_ind in enumerate(worst_img_inds):\n",
    "        plt.subplot(select_top * 2, show_top, (select_top + i) * show_top + j + 1)\n",
    "        plt.imshow(original_val_ds[img_ind][0])\n",
    "        plt.title(f\"Top #{select_top-i} worst feature\\nTop #{j+1} best image\")\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6062473",
   "metadata": {
    "cellId": "made68rjg3nw0vy21xq0h"
   },
   "source": [
    "#### 3.3.2. Как посчитать receptive_field нейрона на каком-то слое?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb14fa2f",
   "metadata": {
    "cellId": "44vponmmosoqe0x00xb8bm"
   },
   "source": [
    "Картинка для понимания:\n",
    "\n",
    "![receptive_field](receptive_field.jpg \"Receptive Field\")\n",
    "\n",
    "Посчитаем относительно только одной из размерностей (H или W), для второй аналогично.\n",
    "\n",
    "$$k_t - \\text{Kernel size on layer t}$$\n",
    "$$s_t - \\text{Stride on layer t}$$\n",
    "$$d_t - \\text{Dilation on layer t}$$\n",
    "$$r_t - \\text{Receptive field of neuron on layer t}$$\n",
    "\n",
    "1. $r_0 = 1$ - на 0-м слое каждый \"нейрон\" (пиксель) хранит в себе информацию только о самом себе\n",
    "2. $r_1 = k_1$ - на 1-м слое каждый нейрон смотрит ровно на $k_1$ пикселей\n",
    "3. $r_2 = (k_2 - 1) * s_1 + k_1$ - на 1-м слое один нейрон смотрит на $k_1$, а каждый следующий сдвинут от него на $s_1$, таких следующих нейронов $k_2 - 1$ штук, поэтому получаем такую формулу для 2-го слоя\n",
    "4. Как перейти к общему случаю? $r_{t+1} = (k_{t+1} - 1) \\cdot j_t + r_t \\longrightarrow$ на t-ом слое один нейрон смотрит на $r_t$, а каждый следующий смещён от него на jump $j_t$ пикселей оригинального изображения, где $j_t = \\prod_{i=1}^{t} s_i$\n",
    "5. Как здесь участвует dilation? $r_{t+1} = ((k_{t+1} - 1) \\cdot d_{t+1} + 1 - 1) \\cdot j_t + r_t = (k_{t+1} - 1) \\cdot d_{t+1} \\cdot j_t + r_t\\longrightarrow$ фактически увеличивает kernel size $k_{t}^* = (k_{t} - 1) \\cdot d_{t} + 1$\n",
    "\n",
    "**Итоговоая формула:**\n",
    "$$ r_{t+1} = (k_{t+1} - 1) \\cdot d_{t+1} \\cdot j_t + r_t = \\sum_{i=1}^{t+1} \\Big( (k_{i} - 1) \\cdot d_{i} \\cdot \\prod_{j=1}^{i} s_j \\Big) + 1$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfc33f0",
   "metadata": {
    "cellId": "cuwdmu8bxbpdk49nu57re",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:28:55.089872Z",
     "iopub.status.busy": "2024-03-05T13:28:55.089023Z",
     "iopub.status.idle": "2024-03-05T13:28:55.113406Z",
     "shell.execute_reply": "2024-03-05T13:28:55.111740Z",
     "shell.execute_reply.started": "2024-03-05T13:28:55.089832Z"
    }
   },
   "outputs": [],
   "source": [
    "conv_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d98967d",
   "metadata": {
    "cellId": "smjxf0ab84dxyx8mlx28y",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:29:16.757536Z",
     "iopub.status.busy": "2024-03-05T13:29:16.756093Z",
     "iopub.status.idle": "2024-03-05T13:29:16.791856Z",
     "shell.execute_reply": "2024-03-05T13:29:16.790366Z",
     "shell.execute_reply.started": "2024-03-05T13:29:16.757458Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_receptive_fields(conv_layers):\n",
    "    def receptive_field(old_receptive_field, jump, kernel_size):\n",
    "        return old_receptive_field + (kernel_size - 1) * jump\n",
    "    \n",
    "    res = [1]\n",
    "    old_receptive_field = 1\n",
    "    jump = 1\n",
    "    for layer in conv_layers:\n",
    "        if isinstance(layer, nn.Conv2d):\n",
    "            k = layer.kernel_size[0]\n",
    "            d = layer.dilation[0]\n",
    "            s = layer.stride[0]\n",
    "        elif isinstance(layer, (nn.MaxPool2d, nn.AvgPool2d)):\n",
    "            k = layer.kernel_size\n",
    "            d = layer.dilation\n",
    "            s = layer.stride\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown layer type {type(layer)}\")\n",
    "        \n",
    "        old_receptive_field = receptive_field(\n",
    "            old_receptive_field,\n",
    "            jump,\n",
    "            (k - 1) * d + 1,\n",
    "        )\n",
    "        jump *= s\n",
    "        res.append(old_receptive_field)\n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "receptive_fields = get_receptive_fields(conv_layers)\n",
    "\n",
    "for i, (layer_, from_, to_) in enumerate(zip(conv_layers, receptive_fields[:-1], receptive_fields[1:])):\n",
    "    layer_type = str(type(layer_)).split(\".\")[-1][:-2]\n",
    "    k = layer_.kernel_size\n",
    "    s = layer_.stride\n",
    "    d = layer_.dilation\n",
    "    if isinstance(k, tuple):\n",
    "        k = k[0]\n",
    "        s = s[0]\n",
    "        d = d[0]\n",
    "    print(f\"#{i: <2}: {layer_type: <9} - k={k} , s={s} , d={d}  ~  changed receptive field  ~  {from_: >3} --> {to_: <3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22601b3b",
   "metadata": {
    "cellId": "ygtfajczyltbp3dbd4qidw"
   },
   "source": [
    "#### 3.3.3. Посмотрим на какие части изображений активируются какие слои"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0727ab5",
   "metadata": {
    "cellId": "ueiz73dq5aq9pioh0vry7b",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:31:14.323987Z",
     "iopub.status.busy": "2024-03-05T13:31:14.322741Z",
     "iopub.status.idle": "2024-03-05T13:31:14.343273Z",
     "shell.execute_reply": "2024-03-05T13:31:14.342106Z",
     "shell.execute_reply.started": "2024-03-05T13:31:14.323945Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "chosen_layers = [3, 6, 9, 12]\n",
    "max_num_channels = 10\n",
    "\n",
    "layer_outputs = defaultdict(list)\n",
    "\n",
    "def extract_output_hook(m, inputs, output, layer_ind):\n",
    "    layer_outputs[layer_ind].append(output[:, :max_num_channels, :, :].cpu().detach().numpy())\n",
    "    return None\n",
    "\n",
    "handles = []\n",
    "\n",
    "for i, module in enumerate(conv_layers):\n",
    "    if i in chosen_layers:\n",
    "        assert module._forward_hooks == OrderedDict(), f\"Delete previous hooks first\\n{i}\\n{module}\\n{module._forward_hooks}\"\n",
    "        handles.append(\n",
    "            module.register_forward_hook(\n",
    "                partial(extract_output_hook, layer_ind=i)\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a09ea00",
   "metadata": {
    "cellId": "ui4vx9lmxnvigmh368vwl",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:31:22.457185Z",
     "iopub.status.busy": "2024-03-05T13:31:22.456283Z",
     "iopub.status.idle": "2024-03-05T13:31:39.796592Z",
     "shell.execute_reply": "2024-03-05T13:31:39.795168Z",
     "shell.execute_reply.started": "2024-03-05T13:31:22.457139Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    for img, _ in tqdm(val_loader):\n",
    "        out = model(img.to(device))\n",
    "model.cpu()\n",
    "\n",
    "for key, values in layer_outputs.items():\n",
    "    layer_outputs[key] = np.concatenate(values, axis=0)\n",
    "\n",
    "for handle in handles:\n",
    "    handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39020b26",
   "metadata": {
    "cellId": "kipwavh4lwi5qlj4uibh",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:31:43.503695Z",
     "iopub.status.busy": "2024-03-05T13:31:43.502850Z",
     "iopub.status.idle": "2024-03-05T13:31:43.519558Z",
     "shell.execute_reply": "2024-03-05T13:31:43.518320Z",
     "shell.execute_reply.started": "2024-03-05T13:31:43.503658Z"
    }
   },
   "outputs": [],
   "source": [
    "layer_outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdebf9a",
   "metadata": {
    "cellId": "aia72phwxx4z9fdmkq4qv",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:31:47.892231Z",
     "iopub.status.busy": "2024-03-05T13:31:47.891009Z",
     "iopub.status.idle": "2024-03-05T13:31:47.913267Z",
     "shell.execute_reply": "2024-03-05T13:31:47.912053Z",
     "shell.execute_reply.started": "2024-03-05T13:31:47.892165Z"
    }
   },
   "outputs": [],
   "source": [
    "layer_outputs[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed139fcd",
   "metadata": {
    "cellId": "g7n7ku6wvz9rwkiu8amto",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:32:16.637209Z",
     "iopub.status.busy": "2024-03-05T13:32:16.636192Z",
     "iopub.status.idle": "2024-03-05T13:32:16.653410Z",
     "shell.execute_reply": "2024-03-05T13:32:16.652223Z",
     "shell.execute_reply.started": "2024-03-05T13:32:16.637156Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Force clear everything up\n",
    "# for module in conv_layers:\n",
    "#     module._forward_hooks = OrderedDict()\n",
    "\n",
    "# del layer_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177e7248",
   "metadata": {
    "cellId": "on1eq16e22dlzpdlccqt3j",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:33:45.577987Z",
     "iopub.status.busy": "2024-03-05T13:33:45.576961Z",
     "iopub.status.idle": "2024-03-05T13:33:45.606413Z",
     "shell.execute_reply": "2024-03-05T13:33:45.605244Z",
     "shell.execute_reply.started": "2024-03-05T13:33:45.577934Z"
    }
   },
   "outputs": [],
   "source": [
    "pad_size = [0]\n",
    "j = 1\n",
    "\n",
    "for module in conv_layers:\n",
    "    p = module.padding\n",
    "    s = module.stride\n",
    "    if isinstance(p, tuple):\n",
    "        p = p[0]\n",
    "        s = s[0]\n",
    "    pad_size.append(pad_size[-1] + p * j)\n",
    "    j *= s\n",
    "    \n",
    "pad_size = pad_size[1:]\n",
    "print(pad_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b47299",
   "metadata": {
    "cellId": "v5309tnlyvn3h1yhwy8kuz",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:35:38.945640Z",
     "iopub.status.busy": "2024-03-05T13:35:38.944531Z",
     "iopub.status.idle": "2024-03-05T13:35:38.970392Z",
     "shell.execute_reply": "2024-03-05T13:35:38.969208Z",
     "shell.execute_reply.started": "2024-03-05T13:35:38.945585Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_best_examples(layer_ind, num_channels=5, num_examples=5):\n",
    "    assert num_channels <= max_num_channels, \"This amount of channels wasn't computed\"\n",
    "    res = np.zeros((num_channels, num_examples, 3), dtype=int)\n",
    "    \n",
    "    p = pad_size[layer_ind]\n",
    "    r = receptive_fields[layer_ind + 1]\n",
    "    h, w = layer_outputs[layer_ind].shape[2:]\n",
    "    for i, channel_ind in enumerate(range(num_channels)):\n",
    "        max_values = np.max(\n",
    "            layer_outputs[layer_ind][:, channel_ind, :, :],\n",
    "            axis=(1, 2),\n",
    "        )\n",
    "        \n",
    "        best_images_inds = np.argsort(-max_values)[:num_examples]\n",
    "        \n",
    "        for j, image_ind in enumerate(best_images_inds):\n",
    "            # На каком изображении из val датасета\n",
    "            res[i, j, 0] = image_ind\n",
    "            # Положение максимальной активации по осям H и W (с учётом смещённости за счёт паддинга)\n",
    "            pos = np.argmax(layer_outputs[layer_ind][image_ind, channel_ind].reshape(-1), axis=0)\n",
    "            res[i, j, 1] = pos // w - p\n",
    "            res[i, j, 2] = pos % w - p\n",
    "            \n",
    "            assert (\n",
    "                np.max(layer_outputs[layer_ind][image_ind, channel_ind]) ==\n",
    "                layer_outputs[layer_ind][image_ind, channel_ind, res[i, j, 1] + p, res[i, j, 2] + p]\n",
    "            ), (\n",
    "                f\"\\n{layer_outputs[layer_ind][image_ind, channel_ind, res[i, j, 1], res[i, j, 2]]}\"\n",
    "                f\"\\n{np.max(layer_outputs[layer_ind][image_ind, channel_ind])}\"\n",
    "            )\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(num_channels, num_examples, figsize=(5 * num_examples, 5 * num_channels))\n",
    "    fig.suptitle(f\"Layer #{layer_ind} activations examples\", y=0.9)\n",
    "    \n",
    "    for i, channel_ind in enumerate(range(num_channels)):\n",
    "        for j, image_ind in enumerate(range(num_examples)):\n",
    "            plt.subplot(num_channels, num_examples, i * num_examples + j + 1)\n",
    "            img = np.clip(de_normalize(val_ds[res[channel_ind, image_ind, 0]][0]), 0, 1)\n",
    "            hh, ww = res[channel_ind, image_ind, 1:]\n",
    "            img = img[max(hh, 0): hh + r, max(ww, 0): ww + r, :]\n",
    "            plt.imshow(img)\n",
    "            plt.title(f\"Channel #{i+1}\\nImage #{j+1} with top activation\")\n",
    "            plt.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d48f41",
   "metadata": {
    "cellId": "s83hbct7r5ilmrddpgnfq",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:35:41.773068Z",
     "iopub.status.busy": "2024-03-05T13:35:41.771888Z",
     "iopub.status.idle": "2024-03-05T13:35:49.637824Z",
     "shell.execute_reply": "2024-03-05T13:35:49.636546Z",
     "shell.execute_reply.started": "2024-03-05T13:35:41.773010Z"
    }
   },
   "outputs": [],
   "source": [
    "find_best_examples(layer_ind=3, num_channels=10, num_examples=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bfc7d8",
   "metadata": {
    "cellId": "0d4zjmr87tn0pw0ma4py3dc",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:36:05.058824Z",
     "iopub.status.busy": "2024-03-05T13:36:05.057766Z",
     "iopub.status.idle": "2024-03-05T13:36:13.106825Z",
     "shell.execute_reply": "2024-03-05T13:36:13.105432Z",
     "shell.execute_reply.started": "2024-03-05T13:36:05.058780Z"
    }
   },
   "outputs": [],
   "source": [
    "find_best_examples(layer_ind=6, num_channels=10, num_examples=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaba851",
   "metadata": {
    "cellId": "8nev98laxzpgn5ag8s2o6",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:36:13.109299Z",
     "iopub.status.busy": "2024-03-05T13:36:13.108623Z",
     "iopub.status.idle": "2024-03-05T13:36:21.042408Z",
     "shell.execute_reply": "2024-03-05T13:36:21.041068Z",
     "shell.execute_reply.started": "2024-03-05T13:36:13.109262Z"
    }
   },
   "outputs": [],
   "source": [
    "find_best_examples(layer_ind=9, num_channels=10, num_examples=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1979f741",
   "metadata": {
    "cellId": "os3ggxxzz2zzrcdhyp0sl",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:36:21.045140Z",
     "iopub.status.busy": "2024-03-05T13:36:21.044541Z",
     "iopub.status.idle": "2024-03-05T13:36:30.853974Z",
     "shell.execute_reply": "2024-03-05T13:36:30.852711Z",
     "shell.execute_reply.started": "2024-03-05T13:36:21.045081Z"
    }
   },
   "outputs": [],
   "source": [
    "find_best_examples(layer_ind=12, num_channels=10, num_examples=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bee3ca",
   "metadata": {
    "cellId": "9hleq9q6xdolo1dpo3429",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:37:23.781150Z",
     "iopub.status.busy": "2024-03-05T13:37:23.780104Z",
     "iopub.status.idle": "2024-03-05T13:37:23.801463Z",
     "shell.execute_reply": "2024-03-05T13:37:23.799985Z",
     "shell.execute_reply.started": "2024-03-05T13:37:23.781093Z"
    }
   },
   "outputs": [],
   "source": [
    "del layer_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f915d3db",
   "metadata": {
    "cellId": "uisbedokkzq9rjro4n9vj"
   },
   "source": [
    "#### 3.3.4. Какая часть изображения ответственна за результат классификации?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad2c681",
   "metadata": {
    "cellId": "keuny81xunf0d4x6g7k3bd",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:37:35.377163Z",
     "iopub.status.busy": "2024-03-05T13:37:35.376080Z",
     "iopub.status.idle": "2024-03-05T13:37:35.586339Z",
     "shell.execute_reply": "2024-03-05T13:37:35.585074Z",
     "shell.execute_reply.started": "2024-03-05T13:37:35.377122Z"
    }
   },
   "outputs": [],
   "source": [
    "img_ind = 4\n",
    "\n",
    "img = val_ds[img_ind][0]\n",
    "img_vis = min_max_scale(de_normalize(img))\n",
    "plt.imshow(img_vis)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafb0c3f",
   "metadata": {
    "cellId": "u1ijgwuiwdbee76qd77d9e",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:37:46.017626Z",
     "iopub.status.busy": "2024-03-05T13:37:46.016673Z",
     "iopub.status.idle": "2024-03-05T13:37:46.097350Z",
     "shell.execute_reply": "2024-03-05T13:37:46.095982Z",
     "shell.execute_reply.started": "2024-03-05T13:37:46.017588Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(img.unsqueeze(0))[0].detach()\n",
    "    probs = F.softmax(out, dim=0).numpy()\n",
    "\n",
    "pred_cl_ind = np.argmax(probs)\n",
    "\n",
    "print(\"\\n\".join(list(map(lambda el: f\"{el[0]: <10} ~ {str(round(el[1], 4))}\", zip(classes, probs)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9825ab",
   "metadata": {
    "cellId": "r993ma7odflihpju7bw6ef",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:38:42.566925Z",
     "iopub.status.busy": "2024-03-05T13:38:42.565920Z",
     "iopub.status.idle": "2024-03-05T13:38:42.592519Z",
     "shell.execute_reply": "2024-03-05T13:38:42.591307Z",
     "shell.execute_reply.started": "2024-03-05T13:38:42.566879Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "assert np.allclose(\n",
    "    probs,\n",
    "    F.softmax(torch.tensor(val_preds[img_ind]), dim=0).numpy(),\n",
    ")\n",
    "\n",
    "relevance = model.fc.weight[pred_cl_ind].detach().numpy() * val_pre_fc_preds[img_ind, :, 0, 0]\n",
    "\n",
    "# class activation map\n",
    "cam = (val_conv_activations[img_ind] * relevance[:, None, None]).sum(0)\n",
    "\n",
    "cam = cv2.resize(cam, val_transform.transforms[0].size)\n",
    "\n",
    "cam = min_max_scale(cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb616401",
   "metadata": {
    "cellId": "1ys5yg4hv9nurl4s25p6m",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:38:56.823955Z",
     "iopub.status.busy": "2024-03-05T13:38:56.823134Z",
     "iopub.status.idle": "2024-03-05T13:38:57.295454Z",
     "shell.execute_reply": "2024-03-05T13:38:57.294299Z",
     "shell.execute_reply.started": "2024-03-05T13:38:56.823888Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.title(\"Image\")\n",
    "plt.imshow(img_vis)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.title(\"Class Activation Map\")\n",
    "plt.imshow(cam)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.title(\"Both\")\n",
    "plt.imshow(img_vis, alpha=0.5)\n",
    "plt.imshow(cam, alpha=0.5)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19c8427",
   "metadata": {
    "cellId": "kvjv517opnflvv55dgzhq",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:39:02.191029Z",
     "iopub.status.busy": "2024-03-05T13:39:02.190132Z",
     "iopub.status.idle": "2024-03-05T13:39:02.214194Z",
     "shell.execute_reply": "2024-03-05T13:39:02.212987Z",
     "shell.execute_reply.started": "2024-03-05T13:39:02.190976Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_cam(img_ind):\n",
    "    img = val_ds[img_ind][0]\n",
    "    img = min_max_scale(de_normalize(img))\n",
    "    \n",
    "    probs = F.softmax(torch.tensor(val_preds[img_ind]), dim=0).numpy()\n",
    "    \n",
    "    pred_cl_ind = np.argmax(probs)\n",
    "    \n",
    "    to_print = list(map(lambda el: f\"{el[0]: <10} ~ {str(round(el[1], 4))}\", zip(classes, probs)))\n",
    "    to_print[targets[img_ind]] = colored(to_print[targets[img_ind]], \"green\")\n",
    "    to_print[pred_cl_ind] = colored(to_print[pred_cl_ind], \"red\")  # , attrs=[\"bold\", \"underline\"])\n",
    "    print(\"\\n\".join(to_print))\n",
    "    \n",
    "    relevance = model.fc.weight[pred_cl_ind].detach().numpy() * val_pre_fc_preds[img_ind, :, 0, 0]\n",
    "\n",
    "    # class activation map\n",
    "    cam = (val_conv_activations[img_ind] * relevance[:, None, None]).sum(0)\n",
    "\n",
    "    cam = cv2.resize(cam, val_transform.transforms[0].size)\n",
    "\n",
    "    cam = min_max_scale(cam)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "    plt.subplot(131)\n",
    "    plt.title(\"Image\")\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(132)\n",
    "    plt.title(\"Class Activation Map\")\n",
    "    plt.imshow(cam)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(133)\n",
    "    plt.title(\"Both\")\n",
    "    plt.imshow(img, alpha=0.5)\n",
    "    plt.imshow(cam, alpha=0.5)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168426aa",
   "metadata": {
    "cellId": "miuky8uocfthpx40k2pov6",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:39:08.176459Z",
     "iopub.status.busy": "2024-03-05T13:39:08.175214Z",
     "iopub.status.idle": "2024-03-05T13:39:08.613630Z",
     "shell.execute_reply": "2024-03-05T13:39:08.612443Z",
     "shell.execute_reply.started": "2024-03-05T13:39:08.176396Z"
    }
   },
   "outputs": [],
   "source": [
    "get_cam(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94f4d19",
   "metadata": {
    "cellId": "0j4ztvwp77i51qyj4r6rclb",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:39:11.133606Z",
     "iopub.status.busy": "2024-03-05T13:39:11.132513Z",
     "iopub.status.idle": "2024-03-05T13:39:11.564190Z",
     "shell.execute_reply": "2024-03-05T13:39:11.562927Z",
     "shell.execute_reply.started": "2024-03-05T13:39:11.133499Z"
    }
   },
   "outputs": [],
   "source": [
    "get_cam(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c8f30c",
   "metadata": {
    "cellId": "4y20a5kzmrl6hafcg1t0yv",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:39:13.682010Z",
     "iopub.status.busy": "2024-03-05T13:39:13.680990Z",
     "iopub.status.idle": "2024-03-05T13:39:14.104013Z",
     "shell.execute_reply": "2024-03-05T13:39:14.102779Z",
     "shell.execute_reply.started": "2024-03-05T13:39:13.681951Z"
    }
   },
   "outputs": [],
   "source": [
    "get_cam(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4d4666",
   "metadata": {
    "cellId": "wbfhyn28a5bjh43aweit6b",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:39:16.099895Z",
     "iopub.status.busy": "2024-03-05T13:39:16.098903Z",
     "iopub.status.idle": "2024-03-05T13:39:16.523126Z",
     "shell.execute_reply": "2024-03-05T13:39:16.521889Z",
     "shell.execute_reply.started": "2024-03-05T13:39:16.099850Z"
    }
   },
   "outputs": [],
   "source": [
    "get_cam(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c2eae3",
   "metadata": {
    "cellId": "rmgmbdmp2mohuoj1kppx",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:39:27.495980Z",
     "iopub.status.busy": "2024-03-05T13:39:27.494889Z",
     "iopub.status.idle": "2024-03-05T13:39:27.510655Z",
     "shell.execute_reply": "2024-03-05T13:39:27.509497Z",
     "shell.execute_reply.started": "2024-03-05T13:39:27.495921Z"
    }
   },
   "outputs": [],
   "source": [
    "val_probs = np.exp(val_preds - val_preds.max()) / np.exp(val_preds - val_preds.max()).sum(1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caef18c",
   "metadata": {
    "cellId": "ml9cq61wm3gzivtljnwf2",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:39:28.319620Z",
     "iopub.status.busy": "2024-03-05T13:39:28.318723Z",
     "iopub.status.idle": "2024-03-05T13:39:28.336614Z",
     "shell.execute_reply": "2024-03-05T13:39:28.335365Z",
     "shell.execute_reply.started": "2024-03-05T13:39:28.319564Z"
    }
   },
   "outputs": [],
   "source": [
    "least_configdent = np.argsort(val_probs.max(1))[:5]\n",
    "least_configdent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee171e",
   "metadata": {
    "cellId": "z198wnclnaa0hxyl2zyg489",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:39:29.508243Z",
     "iopub.status.busy": "2024-03-05T13:39:29.507027Z",
     "iopub.status.idle": "2024-03-05T13:39:29.954799Z",
     "shell.execute_reply": "2024-03-05T13:39:29.953379Z",
     "shell.execute_reply.started": "2024-03-05T13:39:29.508200Z"
    }
   },
   "outputs": [],
   "source": [
    "get_cam(least_configdent[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b0b207",
   "metadata": {
    "cellId": "u4exdwn7f0hy44ju04use",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:39:35.695483Z",
     "iopub.status.busy": "2024-03-05T13:39:35.694410Z",
     "iopub.status.idle": "2024-03-05T13:39:36.123041Z",
     "shell.execute_reply": "2024-03-05T13:39:36.121826Z",
     "shell.execute_reply.started": "2024-03-05T13:39:35.695441Z"
    }
   },
   "outputs": [],
   "source": [
    "get_cam(least_configdent[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56c1bb2",
   "metadata": {
    "cellId": "8hntbyao6m6alxnh4dvulk",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:39:43.391514Z",
     "iopub.status.busy": "2024-03-05T13:39:43.390502Z",
     "iopub.status.idle": "2024-03-05T13:39:43.841190Z",
     "shell.execute_reply": "2024-03-05T13:39:43.839880Z",
     "shell.execute_reply.started": "2024-03-05T13:39:43.391460Z"
    }
   },
   "outputs": [],
   "source": [
    "get_cam(least_configdent[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142637b8",
   "metadata": {
    "cellId": "tr63wf12759xa27c3l3bqe",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:39:52.620255Z",
     "iopub.status.busy": "2024-03-05T13:39:52.619230Z",
     "iopub.status.idle": "2024-03-05T13:39:53.066Z",
     "shell.execute_reply": "2024-03-05T13:39:53.064682Z",
     "shell.execute_reply.started": "2024-03-05T13:39:52.620210Z"
    }
   },
   "outputs": [],
   "source": [
    "get_cam(least_configdent[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9082ba2a",
   "metadata": {
    "cellId": "4czssd3zttzugztty8ztwn"
   },
   "source": [
    "### 3.4. Как посмотреть что ищет слой нейросети, не по данным, а по самой модели?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26621ed4",
   "metadata": {
    "cellId": "od18fx78okhs81v5ib1p"
   },
   "source": [
    "**Feature Visualization by Optimization:**\n",
    "\n",
    "Формально говоря, модель так же дефиренцируема по своим входам, так почему бы нам не \"обучить\" идеальный вход для конкретного нейрона / канала / слоя / выхода / ...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d71bb88",
   "metadata": {
    "cellId": "5tqde14bs06ukezfkam5ia",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:40:20.743696Z",
     "iopub.status.busy": "2024-03-05T13:40:20.742533Z",
     "iopub.status.idle": "2024-03-05T13:40:20.762388Z",
     "shell.execute_reply": "2024-03-05T13:40:20.761244Z",
     "shell.execute_reply.started": "2024-03-05T13:40:20.743620Z"
    }
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57affb4d",
   "metadata": {
    "cellId": "bwc8d49zwynxsdpzmovss"
   },
   "source": [
    "#### 3.4.1. Представление класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08731d1d",
   "metadata": {
    "cellId": "s8dk7vd9qbhf2ott0q9a",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:41:10.827160Z",
     "iopub.status.busy": "2024-03-05T13:41:10.826220Z",
     "iopub.status.idle": "2024-03-05T13:42:34.323604Z",
     "shell.execute_reply": "2024-03-05T13:42:34.322447Z",
     "shell.execute_reply.started": "2024-03-05T13:41:10.827120Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "max_generation_epochs = 4000\n",
    "alpha = 2.\n",
    "alpha_reduce_each = 500\n",
    "alpha_reduce_mul = 0.5\n",
    "draw_each = 100\n",
    "chosen_class = \"cat\"\n",
    "\n",
    "class_ind = cl_to_ind[chosen_class]\n",
    "img_shape = val_ds[0][0].shape\n",
    "synthetic_image = torch.nn.Parameter(torch.rand(len(classes), *img_shape), requires_grad=True)\n",
    "starting_image = synthetic_image[class_ind].detach().numpy().transpose(1, 2, 0)\n",
    "\n",
    "generated_probs = defaultdict(list)\n",
    "optimized_values = defaultdict(list)\n",
    "xx = np.arange(len(classes))\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "synthetic_image = synthetic_image.to(device)\n",
    "synthetic_image.retain_grad()\n",
    "for epoch in trange(max_generation_epochs):\n",
    "    synthetic_image.grad = None\n",
    "    out = model(synthetic_image)\n",
    "    pred_class_logit = out[xx, xx]\n",
    "    pred_class_logit.sum().backward()\n",
    "    synthetic_image.data = synthetic_image.data + alpha * synthetic_image.grad\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        probs = F.softmax(out, dim=1)\n",
    "        pred_class_prob = probs[xx, xx]\n",
    "        for ind in xx:\n",
    "            generated_probs[ind].append(pred_class_prob[ind].item())\n",
    "            optimized_values[ind].append(pred_class_logit[ind].item())\n",
    "        if (epoch + 1) % draw_each == 0:\n",
    "            clear_output(True)\n",
    "            fig = plt.subplots(2, 1, figsize=(20, 8))\n",
    "            \n",
    "            plt.subplot(211)\n",
    "            for ind in xx:\n",
    "                plt.plot(generated_probs[ind])\n",
    "            plt.title(\"Probability of target class\")\n",
    "            plt.xlabel(\"epoch\")\n",
    "            plt.ylabel(\"probability\")\n",
    "            plt.yscale(\"log\")\n",
    "            \n",
    "            plt.subplot(212)\n",
    "            for ind in xx:\n",
    "                plt.plot(optimized_values[ind])\n",
    "            plt.title(\"Logit of target class\")\n",
    "            plt.xlabel(\"epoch\")\n",
    "            \n",
    "            plt.show()\n",
    "        if (epoch + 1) % alpha_reduce_each == 0:\n",
    "            alpha *= alpha_reduce_mul\n",
    "\n",
    "model.cpu()\n",
    "synthetic_image = synthetic_image.cpu()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(starting_image)\n",
    "plt.title(\"Starting image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(min_max_scale(synthetic_image[class_ind].detach().numpy().transpose(1, 2, 0)))\n",
    "plt.title(\"Resulting image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e296d3",
   "metadata": {
    "cellId": "7iclmyhrjwenqg8shm23e",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:42:34.326459Z",
     "iopub.status.busy": "2024-03-05T13:42:34.325533Z",
     "iopub.status.idle": "2024-03-05T13:42:35.719553Z",
     "shell.execute_reply": "2024-03-05T13:42:35.718272Z",
     "shell.execute_reply.started": "2024-03-05T13:42:34.326402Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 5, figsize=(25, 12))\n",
    "\n",
    "for ind in range(10):\n",
    "    plt.subplot(2, 5, ind+1)\n",
    "    plt.imshow(min_max_scale(synthetic_image[ind].detach().numpy().transpose(1, 2, 0)))\n",
    "    plt.title(classes[ind])\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cb4dd2",
   "metadata": {
    "cellId": "ctf6z54o08dayn2z55lypl"
   },
   "source": [
    "Не особенно на что-то похоже...\n",
    "\n",
    "Потому что мы никак не ограничиваем изображение на то, чтобы оно было хоть сколько-то похоже на изображение в нашем понимании.\n",
    "\n",
    "Добавим член, отвечающий за L2-регуляризацию изображения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d95107",
   "metadata": {
    "cellId": "b3fm4sythtfvkigf0dffmr",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:43:17.081250Z",
     "iopub.status.busy": "2024-03-05T13:43:17.079852Z",
     "iopub.status.idle": "2024-03-05T13:44:43.444140Z",
     "shell.execute_reply": "2024-03-05T13:44:43.442828Z",
     "shell.execute_reply.started": "2024-03-05T13:43:17.081207Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "max_generation_epochs = 4000\n",
    "alpha = 4.\n",
    "alpha_reduce_each = 500\n",
    "alpha_reduce_mul = 0.5\n",
    "draw_each = 100\n",
    "chosen_class = \"cat\"\n",
    "l2_coef = 4.\n",
    "\n",
    "class_ind = cl_to_ind[chosen_class]\n",
    "img_shape = val_ds[0][0].shape\n",
    "synthetic_image = torch.nn.Parameter(torch.rand(len(classes), *img_shape), requires_grad=True)\n",
    "starting_image = synthetic_image[class_ind].detach().numpy().transpose(1, 2, 0)\n",
    "\n",
    "generated_probs = defaultdict(list)\n",
    "optimized_values = defaultdict(list)\n",
    "xx = np.arange(len(classes))\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "synthetic_image = synthetic_image.to(device)\n",
    "synthetic_image.retain_grad()\n",
    "for epoch in trange(max_generation_epochs):\n",
    "    synthetic_image.grad = None\n",
    "    out = model(synthetic_image)\n",
    "    pred_class_logit = out[xx, xx]\n",
    "    l2_norm = (synthetic_image**2).sum(dim=(1,2,3)).sqrt().sum(0)\n",
    "    (pred_class_logit.sum() - l2_coef * l2_norm).backward()\n",
    "    synthetic_image.data = synthetic_image.data + alpha * synthetic_image.grad\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        probs = F.softmax(out, dim=1)\n",
    "        pred_class_prob = probs[xx, xx]\n",
    "        for ind in xx:\n",
    "            generated_probs[ind].append(pred_class_prob[ind].item())\n",
    "            optimized_values[ind].append(pred_class_logit[ind].item())\n",
    "        if (epoch + 1) % draw_each == 0:\n",
    "            clear_output(True)\n",
    "            fig = plt.subplots(2, 1, figsize=(20, 8))\n",
    "            \n",
    "            plt.subplot(211)\n",
    "            for ind in xx:\n",
    "                plt.plot(generated_probs[ind])\n",
    "            plt.title(\"Probability of target class\")\n",
    "            plt.xlabel(\"epoch\")\n",
    "            plt.ylabel(\"probability\")\n",
    "            plt.yscale(\"log\")\n",
    "            \n",
    "            plt.subplot(212)\n",
    "            for ind in xx:\n",
    "                plt.plot(optimized_values[ind])\n",
    "            plt.title(\"Logit of target class\")\n",
    "            plt.xlabel(\"epoch\")\n",
    "            \n",
    "            plt.show()\n",
    "        if (epoch + 1) % alpha_reduce_each == 0:\n",
    "            alpha *= alpha_reduce_mul\n",
    "\n",
    "model.cpu()\n",
    "synthetic_image = synthetic_image.cpu()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(starting_image)\n",
    "plt.title(\"Starting image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(min_max_scale(synthetic_image[class_ind].detach().numpy().transpose(1, 2, 0)))\n",
    "plt.title(\"Resulting image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7698238",
   "metadata": {
    "cellId": "18pip0gcqtbg9lpmo82rzj",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:44:43.447327Z",
     "iopub.status.busy": "2024-03-05T13:44:43.446425Z",
     "iopub.status.idle": "2024-03-05T13:44:45.350928Z",
     "shell.execute_reply": "2024-03-05T13:44:45.349326Z",
     "shell.execute_reply.started": "2024-03-05T13:44:43.447275Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 5, figsize=(30, 15))\n",
    "\n",
    "for ind in range(10):\n",
    "    plt.subplot(2, 5, ind+1)\n",
    "    plt.imshow(min_max_scale(synthetic_image[ind].detach().numpy().transpose(1, 2, 0)))\n",
    "    plt.title(classes[ind])\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654968da",
   "metadata": {
    "cellId": "xo9oyqklrco2t3vwi06z9l",
    "execution": {
     "iopub.execute_input": "2024-03-05T13:57:53.646530Z",
     "iopub.status.busy": "2024-03-05T13:57:53.645483Z",
     "iopub.status.idle": "2024-03-05T13:57:53.662706Z",
     "shell.execute_reply": "2024-03-05T13:57:53.661548Z",
     "shell.execute_reply.started": "2024-03-05T13:57:53.646490Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_tensor = torch.tensor(val_transform.transforms[-1].mean).unsqueeze(0).to(device)\n",
    "std_tensor = torch.tensor(val_transform.transforms[-1].std).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae78321b",
   "metadata": {
    "cellId": "cqvrjq1a0va97cizycdr6",
    "execution": {
     "iopub.execute_input": "2024-03-05T14:00:14.268406Z",
     "iopub.status.busy": "2024-03-05T14:00:14.267040Z",
     "iopub.status.idle": "2024-03-05T14:01:40.734199Z",
     "shell.execute_reply": "2024-03-05T14:01:40.732821Z",
     "shell.execute_reply.started": "2024-03-05T14:00:14.268342Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "max_generation_epochs = 4000\n",
    "alpha = 4.\n",
    "alpha_reduce_each = 500\n",
    "alpha_reduce_mul = 0.5\n",
    "draw_each = 100\n",
    "chosen_class = \"cat\"\n",
    "reg_coef = 10.\n",
    "\n",
    "class_ind = cl_to_ind[chosen_class]\n",
    "img_shape = val_ds[0][0].shape\n",
    "synthetic_image = torch.nn.Parameter(torch.rand(len(classes), *img_shape), requires_grad=True)\n",
    "starting_image = synthetic_image[class_ind].detach().numpy().transpose(1, 2, 0)\n",
    "\n",
    "generated_probs = defaultdict(list)\n",
    "optimized_values = defaultdict(list)\n",
    "xx = np.arange(len(classes))\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "synthetic_image = synthetic_image.to(device)\n",
    "synthetic_image.retain_grad()\n",
    "for epoch in trange(max_generation_epochs):\n",
    "    synthetic_image.grad = None\n",
    "    out = model(synthetic_image)\n",
    "    pred_class_logit = out[xx, xx]\n",
    "    regularization = ((synthetic_image.mean((0, 2, 3)) - mean_tensor)**2).sum() + ((synthetic_image.std((0, 2, 3)) - std_tensor)**2).sum()\n",
    "    (pred_class_logit.sum() - reg_coef * regularization).backward()\n",
    "    synthetic_image.data = synthetic_image.data + alpha * synthetic_image.grad\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        probs = F.softmax(out, dim=1)\n",
    "        pred_class_prob = probs[xx, xx]\n",
    "        for ind in xx:\n",
    "            generated_probs[ind].append(pred_class_prob[ind].item())\n",
    "            optimized_values[ind].append(pred_class_logit[ind].item())\n",
    "        if (epoch + 1) % draw_each == 0:\n",
    "            clear_output(True)\n",
    "            fig = plt.subplots(2, 1, figsize=(20, 8))\n",
    "            \n",
    "            plt.subplot(211)\n",
    "            for ind in xx:\n",
    "                plt.plot(generated_probs[ind])\n",
    "            plt.title(\"Probability of target class\")\n",
    "            plt.xlabel(\"epoch\")\n",
    "            plt.ylabel(\"probability\")\n",
    "            plt.yscale(\"log\")\n",
    "            \n",
    "            plt.subplot(212)\n",
    "            for ind in xx:\n",
    "                plt.plot(optimized_values[ind])\n",
    "            plt.title(\"Logit of target class\")\n",
    "            plt.xlabel(\"epoch\")\n",
    "            \n",
    "            plt.show()\n",
    "        if (epoch + 1) % alpha_reduce_each == 0:\n",
    "            alpha *= alpha_reduce_mul\n",
    "\n",
    "model.cpu()\n",
    "synthetic_image = synthetic_image.cpu()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(starting_image)\n",
    "plt.title(\"Starting image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(min_max_scale(synthetic_image[class_ind].detach().numpy().transpose(1, 2, 0)))\n",
    "plt.title(\"Resulting image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb4944f",
   "metadata": {
    "cellId": "idv0d8egeyhq206w2ng3a",
    "execution": {
     "iopub.execute_input": "2024-03-05T14:01:50.360035Z",
     "iopub.status.busy": "2024-03-05T14:01:50.358874Z",
     "iopub.status.idle": "2024-03-05T14:01:52.275834Z",
     "shell.execute_reply": "2024-03-05T14:01:52.274043Z",
     "shell.execute_reply.started": "2024-03-05T14:01:50.359977Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 5, figsize=(30, 15))\n",
    "\n",
    "for ind in range(10):\n",
    "    plt.subplot(2, 5, ind+1)\n",
    "    plt.imshow(min_max_scale(synthetic_image[ind].detach().numpy().transpose(1, 2, 0)))\n",
    "    plt.title(classes[ind])\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc893df",
   "metadata": {
    "cellId": "rdunep4gq44s0qz7zhgm7"
   },
   "source": [
    "Чтобы оптимизационными и генеративными методами получить результаты лучше - много всего, поэтому сейчас остановимся здесь. Больше найдёте в специализированных курсах по CV, NLP, генеративкам, etc.\n",
    "\n",
    "Полезные ссылки, если хочется посмотреть/ попробовать ещё:\n",
    "\n",
    "* https://distill.pub/2017/feature-visualization\n",
    "* https://yosinski.com/deepvis\n",
    "* https://github.com/utkuozbulak/pytorch-cnn-visualizations\n",
    "* https://github.com/yosinski/deep-visualization-toolbox\n",
    "* https://github.com/tensorflow/lucid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013ae3ea",
   "metadata": {
    "cellId": "u9f3d9urvggrt8x732yts"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "notebookId": "00017dc0-69ed-43c3-b989-8029237a77d0",
  "notebookPath": "Sem5 - Interpretation/sem5_interpretation.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
